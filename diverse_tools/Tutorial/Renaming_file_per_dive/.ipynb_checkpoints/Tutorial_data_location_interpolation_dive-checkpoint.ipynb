{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a82d8275",
   "metadata": {},
   "source": [
    "# Importando módulos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e98d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import obspy\n",
    "from obspy.taup import TauPyModel\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from obspy import read,UTCDateTime,Trace\n",
    "from obspy.clients.fdsn import Client\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "#para plotar as figuras\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.transforms import offset_copy\n",
    "import matplotlib.ticker as ticker\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.dates as mdates\n",
    "from mpl_toolkits.axes_grid1.inset_locator import InsetPosition,inset_axes\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.dates import YearLocator, MonthLocator, DayLocator, HourLocator, MinuteLocator, SecondLocator, DateFormatter\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
    "\n",
    "from datetime import datetime,timedelta,date\n",
    "from tqdm import tqdm\n",
    "\n",
    "from shapely.geometry.polygon import LinearRing\n",
    "\n",
    "import cartopy.io.shapereader as shpreader\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "from IPython.display import HTML\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4f9f8f",
   "metadata": {},
   "source": [
    "# Inputs e Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38736b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_OUTPUT = '/run/media/dIOGOLOC/8d2362fc-3b46-49a7-a864-19b2a6ad097b/diogoloc/dados_posdoc/gliders_project/OUTPUT/'\n",
    "\n",
    "MSEED_INPUT = \"/run/media/dIOGOLOC/8d2362fc-3b46-49a7-a864-19b2a6ad097b/diogoloc/dados_posdoc/gliders_project/OUTPUT/MSEED_old/\"\n",
    "\n",
    "METADATA_OUTPUT = \"/run/media/dIOGOLOC/8d2362fc-3b46-49a7-a864-19b2a6ad097b/diogoloc/dados_posdoc/gliders_project/OUTPUT/METADATA/\"\n",
    "\n",
    "filename_csv = '/run/media/dIOGOLOC/8d2362fc-3b46-49a7-a864-19b2a6ad097b/diogoloc/dados_posdoc/gliders_project/gliders_data/info_csv/metadados_glider_acustico_pmpas-bs.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebce2fe",
   "metadata": {},
   "source": [
    "# Extraindo informações dos arquivos \".mseed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a67b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_MSEED = sorted(glob.glob(MSEED_INPUT+'*/*/*.mseed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2378588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mseed_data_2_dataframe(i):\n",
    "    subdir, filename_wav = os.path.split(i)\n",
    "    filename = filename_wav.split('.mseed')[0]\n",
    "    if 'pa' in filename.split('_')[0]:\n",
    "        mergulho = filename.split('_')[0].split('a')[1]\n",
    "        stream_number = filename.split('_')[1]\n",
    "\n",
    "        year_month_day = filename.split('_')[2]\n",
    "        hour_minute_second = filename.split('_')[3]\n",
    "\n",
    "        year = int('20'+year_month_day[:2])\n",
    "        month = int(year_month_day[2:4])\n",
    "        day = int(year_month_day[4:])\n",
    "\n",
    "        hour = int(hour_minute_second[:2])\n",
    "        minute = int(hour_minute_second[2:4])\n",
    "        second = int(hour_minute_second[4:])\n",
    "\n",
    "        d = UTCDateTime(datetime(year,month,day,hour,minute,second).isoformat())\n",
    "\n",
    "\n",
    "    if 'pa' in filename.split('_')[2]:\n",
    "\n",
    "        mergulho = filename.split('_')[2].split('a')[1]\n",
    "        stream_number = filename.split('_')[3]\n",
    "\n",
    "        year_month_day = filename.split('_')[0]\n",
    "        hour_minute_second = filename.split('_')[1]\n",
    "\n",
    "        year = int('20'+year_month_day[:2])\n",
    "        month = int(year_month_day[2:4])\n",
    "        day = int(year_month_day[4:])\n",
    "\n",
    "        hour = int(hour_minute_second[:2])\n",
    "        minute = int(hour_minute_second[2:4])\n",
    "        second = int(hour_minute_second[4:])\n",
    "\n",
    "        d = UTCDateTime(datetime(year,month,day,hour,minute,second).isoformat())\n",
    "        \n",
    "    \n",
    "    st = read(i,headonly=True)   \n",
    "    #----------------------------\n",
    "    #Starting Dataframe\n",
    "\n",
    "    starttime = st[0].stats.starttime.datetime\n",
    "    endtime = st[0].stats.endtime.datetime\n",
    "    sampling_rate = st[0].stats.sampling_rate\n",
    "    npts = st[0].stats.npts\n",
    "\n",
    "    \n",
    "    df = pd.DataFrame([[filename],[mergulho],[stream_number],[starttime],[endtime],[sampling_rate],[npts]], index=['filename_mseed', 'mergulho', 'stream_number','starttime','endtime','sampling_rate','npts']).T\n",
    "    \n",
    "    #Ending Dataframe\n",
    "    #----------------------------\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4c7652",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_mseed_lst = []\n",
    "\n",
    "with Pool(processes=8) as p:\n",
    "    max_ = len(filenames_MSEED)\n",
    "    with tqdm(total=max_) as pbar:\n",
    "        for result in p.imap_unordered(mseed_data_2_dataframe,filenames_MSEED):\n",
    "            pbar.update()\n",
    "            pandas_mseed_lst.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1380549",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_mseed_final = pd.concat(pandas_mseed_lst, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dc41a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_mseed_final['starttime'] = pd.to_datetime(dataframe_mseed_final.starttime, format='%Y-%m-%d %H:%M:%S')\n",
    "dataframe_mseed_final['endtime'] = pd.to_datetime(dataframe_mseed_final.endtime, format='%Y-%m-%d %H:%M:%S')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a6ca54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_mseed_final.sort_values(by='starttime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424dc605",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_mseed_final['date'] = dataframe_mseed_final['starttime'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610fe37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_mseed_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bccb0c9",
   "metadata": {},
   "source": [
    "# Extraindo informações dos arquivos \".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d04cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_csv = pd.read_csv(filename_csv,parse_dates=['time'])\n",
    "dataframe_csv.sort_values(by='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd2e7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = dataframe_csv.groupby(\"filename\").agg(pd.Series.tolist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001eeaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv['filename_mseed'] = df_csv.index.str.replace('_rms_spl3.mat', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad5db63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv.sort_values(by='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dc7b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_to_mergulho_stream(filename):\n",
    "    if 'pa' in filename.split('_')[0]:\n",
    "        mergulho = filename.split('_')[0].split('a')[1]\n",
    "\n",
    "    if 'pa' in filename.split('_')[2]:\n",
    "        mergulho = filename.split('_')[2].split('a')[1]\n",
    "    \n",
    "    return mergulho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde6d5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_media(lista):\n",
    "    if len(lista) == 0:\n",
    "        return None  # Retorna None se a lista estiver vazia para evitar erros\n",
    "    else:\n",
    "        return pd.Series(lista).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ece4ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(l):\n",
    "    return l[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12c590e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv['mergulho'] = df_csv['filename_mseed'].apply(name_to_mergulho_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d18f096",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv['date'] = df_csv['time'].apply(calcular_media).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2eb186",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7033d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv['lat'] =  df_csv['latitude'].apply(calcular_media)\n",
    "df_csv['lon'] =  df_csv['longitude'].apply(calcular_media)\n",
    "df_csv['dep'] =  df_csv['depth'].apply(calcular_media)\n",
    "df_csv['time'] =  df_csv['time'].apply(flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19efdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv_mean = df_csv.drop(columns=['latitude','longitude','depth',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40a060f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063c1023",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mergulho = df_csv_mean.groupby([\"date\", \"mergulho\"]).agg(pd.Series.tolist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c74ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mergulho.sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9c76d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mergulho['lat'] =  df_mergulho['lat'].apply(calcular_media)\n",
    "df_mergulho['lon'] =  df_mergulho['lon'].apply(calcular_media)\n",
    "df_mergulho['dep'] =  df_mergulho['dep'].apply(calcular_media)\n",
    "df_mergulho['time'] =  df_mergulho['time'].apply(flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231d7875",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mergulho_feather = df_mergulho.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20840dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mergulho_feather['date_nettab'] = df_mergulho_feather['time'].dt.strftime('%Y/%j[:%H%M]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c350eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mergulho_feather['station_nettab'] = df_mergulho_feather['time'].dt.strftime('G%H%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178faeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mergulho_feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5532d6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montando a tabela com os nome dos gliders:\n",
    "\n",
    "glider_information_dic = {\n",
    "'name':['SG618',\n",
    "'SG618',\n",
    "'SG612',\n",
    "'SG612',\n",
    "'SG612',\n",
    "'SG612',\n",
    "'SG612',\n",
    "'SG612',\n",
    "'SG612',\n",
    "'SG569',\n",
    "'SG570',\n",
    "'SG571',\n",
    "'SG612',\n",
    "'SG612',\n",
    "'SG612',\n",
    "'SG571',\n",
    "'SG612',\n",
    "'SG612',\n",
    "'SG612',\n",
    "'SG612',\n",
    "'SG612',\n",
    "'SG657',\n",
    "'SG656',\n",
    "'SG657',\n",
    "'SG657',\n",
    "'SG657',\n",
    "'SG656',\n",
    "'SG656',\n",
    "'SG657',\n",
    "'SG656',\n",
    "'SG657',\n",
    "'SG657',\n",
    "'SG657'\n",
    "],\n",
    "'start':['10/11/2015',\n",
    "'08/01/2016',\n",
    "'02/02/2016',\n",
    "'07/07/2016',\n",
    "'16/08/2016',\n",
    "'16/09/2016',\n",
    "'21/10/2016',\n",
    "'20/11/2016',\n",
    "'14/01/2017',\n",
    "'17/02/2017',\n",
    "'24/03/2017',\n",
    "'03/06/2017',\n",
    "'12/07/2017',\n",
    "'17/08/2017',\n",
    "'04/10/2017',\n",
    "'29/10/2017',\n",
    "'10/12/2017',\n",
    "'20/01/2018',\n",
    "'22/02/2018',\n",
    "'22/05/2018',\n",
    "'06/07/2018',\n",
    "'29/08/2018',\n",
    "'03/10/2018',\n",
    "'13/11/2018',\n",
    "'28/12/2018',\n",
    "'10/02/2019',\n",
    "'23/03/2019',\n",
    "'29/06/2019',\n",
    "'19/08/2019',\n",
    "'04/09/2019',\n",
    "'15/10/2019',\n",
    "'02/12/2019',\n",
    "'02/01/2020'    \n",
    "],\n",
    "'end':['20/12/2015',\n",
    "'02/02/2016',\n",
    "'20/04/2016',\n",
    "'16/08/2016',\n",
    "'16/09/2016',\n",
    "'15/10/2016',\n",
    "'20/11/2016',\n",
    "'11/01/2017',\n",
    "'16/02/2017',\n",
    "'24/03/2017',\n",
    "'30/04/2017',\n",
    "'12/07/2017',\n",
    "'16/08/2017',\n",
    "'04/10/2017',\n",
    "'28/10/2017',\n",
    "'09/12/2017',\n",
    "'20/01/2018',\n",
    "'22/02/2018',\n",
    "'05/04/2018',\n",
    "'06/07/2018',\n",
    "'22/07/2018',\n",
    "'03/10/2018',\n",
    "'14/11/2018',\n",
    "'23/12/2018',\n",
    "'05/01/2019',\n",
    "'14/03/2019',\n",
    "'01/05/2019',\n",
    "'31/07/2019',\n",
    "'28/08/2019',\n",
    "'10/10/2019',\n",
    "'30/11/2019',\n",
    "'31/12/2019',\n",
    "'11/12/2021'\n",
    "]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2f123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GL_info = pd.DataFrame.from_dict(glider_information_dic)\n",
    "GL_info['start'] = pd.to_datetime(GL_info.start, format='%d/%m/%Y')\n",
    "GL_info['end'] = pd.to_datetime(GL_info.end, format='%d/%m/%Y')\n",
    "\n",
    "GL_info['start'] = GL_info['start'].dt.date \n",
    "GL_info['end'] = GL_info['end'].dt.date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459119cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "GL_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728aa104",
   "metadata": {},
   "outputs": [],
   "source": [
    "GL_info.plot('name','start','scatter',c='k',ylabel='Data',xlabel='Modelo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1fedc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_mergulho_feather.iterrows():\n",
    "    # Station lines (one line per station/sensor/epoch) # code description datalogger%sn seismometer%sn # sampling orientation lat. lon. elev. depth. start end\n",
    "    #Sl: UNAP \"Uni-Iquique/Chile\"   DM24%A1383 CMG-3ESP/60%T34622 100 ZNE -20.24393 -70.14041 0.0    0.0 2009/134 \n",
    "    \n",
    "    # Select DataFrame rows between two dates\n",
    "    \n",
    "    filtro = (i[1].date >= GL_info[\"start\"]) & (i[1].date < GL_info[\"end\"])\n",
    "\n",
    "    # Using pandas.DataFrame.loc to Filter Rows by Dates\n",
    "    \n",
    "    df2 = GL_info[filtro]\n",
    "   \n",
    "    print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d3dde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('readme.txt', 'w') as f:\n",
    "    for line in lines:\n",
    "        f.write(line)\n",
    "        f.write('\\n')\n",
    "\n",
    "for i in df_mergulho_feather.iterrows():\n",
    "    # Station lines (one line per station/sensor/epoch) # code description datalogger%sn seismometer%sn # sampling orientation lat. lon. elev. depth. start end\n",
    "    #Sl: UNAP \"Uni-Iquique/Chile\"   DM24%A1383 CMG-3ESP/60%T34622 100 ZNE -20.24393 -70.14041 0.0    0.0 2009/134 \n",
    "    \n",
    "    # Select DataFrame rows between two dates\n",
    "    \n",
    "    filtro = (i[1].date > GL_info[\"start\"]) & (i[1].date < GL_info[\"end\"])\n",
    "\n",
    "    # Using pandas.DataFrame.loc to Filter Rows by Dates\n",
    "    \n",
    "    df2 = GL_info[filtro]\n",
    "   \n",
    "    print('Sl: '+i[1].station_nettab+' Glider:'+df2['name'].values[0]+' SENSOR'+' '+'REGISTER'+' 100 Z '+str(i[1].lat)+' '+str(i[1].lon)+' 0 0 '+i[1].date_nettab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8103f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mergulho_feather.to_feather('/home/dIOGOLOC/Documents/df_mergulho.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b3be7c",
   "metadata": {},
   "source": [
    "# Plotando o dataframe com os mergulhos: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a642f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#########################################################################################################################################################\n",
    "#Figure \n",
    "\n",
    "# set up the plot and create a GeoAxes:\n",
    "proj = ccrs.PlateCarree()\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(16,16))\n",
    "ax = plt.subplot(1, 1, 1, projection=proj)\n",
    "                    \n",
    "# ----------------------------------------------------------------------------------------------------------\n",
    "# Limit the extent of the map to a small longitude/latitude range.\n",
    "latmin=-30\n",
    "latmax=-20\n",
    "lonmin=-50\n",
    "lonmax=-40\n",
    "\n",
    "ax.set_extent([lonmin,lonmax, latmin, latmax], crs=ccrs.Geodetic())\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------\n",
    "# Ploting lat/lon values\n",
    "                \n",
    "h = ax.scatter(df_mergulho['lon'].values,df_mergulho['lat'].values,c=np.array([mdates.date2num(i) for i in df_mergulho['time'].values]),marker='o',alpha=0.8,cmap='plasma',s=75,transform=proj)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------\n",
    "# Adding background map \n",
    "ax.add_feature(cfeature.LAND)\n",
    "ax.add_feature(cfeature.OCEAN)\n",
    "ax.add_feature(cfeature.COASTLINE,linewidth=0.3)\n",
    "ax.add_feature(cfeature.BORDERS, linestyle=':',linewidth=0.3)\n",
    "ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,linewidth=1, color='gray', alpha=0.5, linestyle='--')\n",
    "    \n",
    "# ----------------------------------------------------------------------------------------------------------\n",
    "# Adding colorbar\n",
    "divider = make_axes_locatable(ax)\n",
    "ax_cb = divider.new_horizontal(size=\"1%\", pad=0.6, axes_class=plt.Axes)\n",
    "\n",
    "fig.add_axes(ax_cb)\n",
    "cb = plt.colorbar(h, cax=ax_cb)\n",
    "cb.ax.yaxis.set_major_formatter(mdates.DateFormatter('%d-%m-%y'))\n",
    "   \n",
    "# ----------------------------------------------------------------------------------------------------------\n",
    "# Adding global location map\n",
    "# inset location relative to main plot (ax) in normalized units\n",
    "inset_x = 0\n",
    "inset_y = 1\n",
    "inset_size = 0.25\n",
    "\n",
    "# Adding Geoaxes\n",
    "ax2 = plt.axes([0, 0, 1, 1], projection=ccrs.Orthographic(central_latitude=(latmin + latmax)/2,central_longitude=(lonmin + lonmax) / 2))\n",
    "ax2.set_global()\n",
    "\n",
    "# Adding background map \n",
    "ax2.add_feature(cfeature.LAND)\n",
    "ax2.add_feature(cfeature.OCEAN)\n",
    "ax2.add_feature(cfeature.COASTLINE)\n",
    "\n",
    "# Adding inset geoaxes position\n",
    "ip = InsetPosition(ax, [inset_x - inset_size / 2,\n",
    "                          inset_y - inset_size / 2,\n",
    "                          inset_size,inset_size])\n",
    "    \n",
    "ax2.set_axes_locator(ip)\n",
    "\n",
    "\n",
    "# Adding red rectangle position\n",
    "nvert = 100\n",
    "lons = np.r_[np.linspace(lonmin, lonmin, nvert),\n",
    "                                 np.linspace(lonmin, lonmax, nvert),\n",
    "                                 np.linspace(lonmax, lonmax, nvert)].tolist()\n",
    "    \n",
    "lats = np.r_[np.linspace(latmin, latmax, nvert),\n",
    "                                 np.linspace(latmax, latmax, nvert),\n",
    "                                 np.linspace(latmax, latmin, nvert)].tolist()\n",
    "\n",
    "ring = LinearRing(list(zip(lons, lats)))\n",
    "ax2.add_geometries([ring], ccrs.PlateCarree(),facecolor='none', edgecolor='red', linewidth=0.75)\n",
    "\n",
    "        \n",
    "# ----------------------------------------------------------------------------------------------------------\n",
    "# Saving figure\n",
    "#os.makedirs(FOLDER_OUTPUT+'FIGURAS/INTERP_MSEED/'+st[0].stats.starttime.strftime('%Y')+'/'+st[0].stats.starttime.strftime('%Y-%m-%d')+'/',exist_ok=True)\n",
    "#fig.savefig(FOLDER_OUTPUT+'FIGURAS/INTERP_MSEED/'+st[0].stats.starttime.strftime('%Y')+'/'+st[0].stats.starttime.strftime('%Y-%m-%d')+'/'+'interp_mseed_'+file_n_meta+'.png')\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eda222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up plotting\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "\n",
    "h = ax.scatter(df_mergulho['lon'].values,df_mergulho['lat'].values,c=np.array([mdates.date2num(i) for i in df_mergulho['time'].values]),marker='o',alpha=0.8,cmap='plasma',s=75,transform=proj)\n",
    "\n",
    "\n",
    "ax.plot(ttime,tdata,c='k',lw=0.1,alpha=0.3)\n",
    "line, = ax.plot([],[],c='r', lw=0.5,alpha=0.7)\n",
    "ax.set_xlim(ttime[0],ttime[-1])\n",
    "ax.set_ylim(tdata.min(), tdata.max())\n",
    "\n",
    "ax.set_yticks([])\n",
    "\n",
    "# methods for animation\n",
    "def init():\n",
    "    line.set_data([],[])\n",
    "    return line,\n",
    "\n",
    "def animate(i):\n",
    "    y = wave_to_plot[i]\n",
    "    x = time_to_plot[i]\n",
    "    line.set_data(x,y)\n",
    "\n",
    "    return line,\n",
    "\n",
    "# Save the animation\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init,frames=len(wave_to_plot))\n",
    "HTML(anim.to_jshtml())\n",
    "\n",
    "# Save the animation as an \n",
    "f = r\"/home/diogoloc/dados_posdoc/ON02_analysis/Figuras/Localizacao_navio_ponte_ON_ON02.mp4\" \n",
    "writervideo = animation.FFMpegWriter(fps=10) \n",
    "anim.save(f, writer=writervideo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087ed6f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
