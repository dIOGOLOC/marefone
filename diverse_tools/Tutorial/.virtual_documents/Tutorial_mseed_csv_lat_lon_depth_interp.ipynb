


import obspy
from obspy.taup import TauPyModel

from multiprocessing import Pool
from obspy import read,UTCDateTime,Trace
from obspy.clients.fdsn import Client
import os
import glob
import numpy as np
from collections import defaultdict
import pandas as pd

#para plotar as figuras
import matplotlib.pyplot as plt
from matplotlib.transforms import offset_copy
import matplotlib.ticker as ticker
from mpl_toolkits.axes_grid1 import make_axes_locatable
from matplotlib.colors import ListedColormap
import matplotlib.dates as mdates
from mpl_toolkits.axes_grid1.inset_locator import InsetPosition,inset_axes
import matplotlib.colors as colors
import matplotlib.cm as cm
from matplotlib.dates import YearLocator, MonthLocator, DayLocator, HourLocator, MinuteLocator, SecondLocator, DateFormatter
from matplotlib.ticker import MultipleLocator, FormatStrFormatter

from datetime import datetime,timedelta,date
from tqdm import tqdm

from shapely.geometry.polygon import LinearRing

import cartopy.io.shapereader as shpreader
import cartopy.crs as ccrs
import cartopy.feature as cfeature





FOLDER_OUTPUT = '/media/sysop/14f7ead0-5dcb-4557-a139-55dbb404d11a/diogoloc/dados_posdoc/Gliders_DATA/OUTPUT/'

FEATHER_OUTPUT = '/media/sysop/14f7ead0-5dcb-4557-a139-55dbb404d11a/diogoloc/dados_posdoc/Gliders_DATA/OUTPUT/FEATHER/'

MSEED_INPUT = "/media/sysop/14f7ead0-5dcb-4557-a139-55dbb404d11a/diogoloc/dados_posdoc/Gliders_DATA/DATA_GLIDER_2024/"





filenames_MSEED = sorted(glob.glob(MSEED_INPUT+'*/GL/*/*/*'))


def mseed_data_2_dataframe(i):
    subdir, filename_wav = os.path.split(i)
    filename = filename_wav.split('.mseed')[0]
    if 'pa' in filename.split('_')[0]:
        mergulho = filename.split('_')[0].split('a')[1]
        stream_number = filename.split('_')[1]

        year_month_day = filename.split('_')[2]
        hour_minute_second = filename.split('_')[3]

        year = int('20'+year_month_day[:2])
        month = int(year_month_day[2:4])
        day = int(year_month_day[4:])

        hour = int(hour_minute_second[:2])
        minute = int(hour_minute_second[2:4])
        second = int(hour_minute_second[4:])

        d = UTCDateTime(datetime(year,month,day,hour,minute,second).isoformat())


    if 'pa' in filename.split('_')[2]:

        mergulho = filename.split('_')[2].split('a')[1]
        stream_number = filename.split('_')[3]

        year_month_day = filename.split('_')[0]
        hour_minute_second = filename.split('_')[1]

        year = int('20'+year_month_day[:2])
        month = int(year_month_day[2:4])
        day = int(year_month_day[4:])

        hour = int(hour_minute_second[:2])
        minute = int(hour_minute_second[2:4])
        second = int(hour_minute_second[4:])

        d = UTCDateTime(datetime(year,month,day,hour,minute,second).isoformat())
        
    
    st = read(i,headonly=True)   
    #----------------------------
    #Starting Dataframe

    starttime = st[0].stats.starttime.datetime
    endtime = st[0].stats.endtime.datetime
    sampling_rate = st[0].stats.sampling_rate
    npts = st[0].stats.npts

    
    df = pd.DataFrame([[filename],[mergulho],[stream_number],[starttime],[endtime],[sampling_rate],[npts]], index=['filename_mseed', 'mergulho', 'stream_number','starttime','endtime','sampling_rate','npts']).T
    
    #Ending Dataframe
    #----------------------------
    return df


pandas_mseed_lst = []

with Pool(processes=8) as p:
    max_ = len(filenames_MSEED)
    with tqdm(total=max_) as pbar:
        for result in p.imap_unordered(mseed_data_2_dataframe,filenames_MSEED):
            pbar.update()
            pandas_mseed_lst.append(result)


dataframe_mseed_final = pd.concat(pandas_mseed_lst, ignore_index=True)


dataframe_mseed_final.sort_values(by='starttime')


dataframe_mseed_final['duration'] = (dataframe_mseed_final['endtime'] - dataframe_mseed_final['starttime']).dt.total_seconds() / 60


dataframe_mseed_final.sort_values(by='starttime')


dataframe_mseed_final_duration = dataframe_mseed_final.groupby("stream_number")['duration'].mean()


dataframe_mseed_final_duration_max = dataframe_mseed_final.groupby("stream_number")['duration'].max()


dataframe_mseed_final


ano_lst = sorted(list(set(dataframe_mseed_final['starttime'].dt.year)))
ano_lst


fig, axes = plt.subplots(len(ano_lst),2,sharex='col',figsize=(20,10))

for i,j in enumerate(ano_lst):
    ax = axes[i][0]
    ax1 = axes[i][1]
    # ------
    # Stream
    # ------
    dataframe_mseed_final_year = dataframe_mseed_final[dataframe_mseed_final['starttime'].dt.year == j]

    dataframe_mseed_final_duration = dataframe_mseed_final_year.groupby("stream_number")['duration'].mean()
    dataframe_mseed_final_duration_max = dataframe_mseed_final_year.groupby("stream_number")['duration'].max()
    
    # Plotar o histograma da coluna
    ax.hist(sorted(dataframe_mseed_final_year['stream_number']), bins=len(dataframe_mseed_final_year['stream_number'].unique())*1, ec='k',fc='k')

    # Configurar o título e rótulos dos eixos
    ax.set_ylabel('Frequency')
    
    ax.text(0.95, 0.9, 'year: '+str(j), fontsize=12, ha='right', va='center', transform=ax.transAxes)
    ax.text(0.95, 0.75, 'files(n): '+str(len(dataframe_mseed_final_year)), fontsize=12, ha='right', va='center', transform=ax.transAxes)

    # Set major xticks
    ax.xaxis.set_major_locator(MultipleLocator(10))
    ax.tick_params(axis='x', rotation=45)

    # Set minor xticks
    ax.xaxis.set_minor_locator(MultipleLocator(1))


    # --------
    # Duration
    # --------

    # Plotar o histograma da coluna
    ax1.bar(x=dataframe_mseed_final_duration_max.index.values,height=dataframe_mseed_final_duration_max.values,align='edge',width=1,alpha=1,ec='k',fc='k',label='Max')
    ax1.bar(x=dataframe_mseed_final_duration.index.values,height=dataframe_mseed_final_duration.values,align='edge',width=1,alpha=1,ec='gray',fc='none',label='Média')

    # Configurar o título e rótulos dos eixos
    ax1.set_ylabel('Duration (min)')
    ax1.set_ylim(0,10)
    
    ax1.text(0.95, 0.9, 'year: '+str(j), fontsize=12, ha='right', va='center', transform=ax1.transAxes)
    ax1.text(0.95, 0.75, 'mean(min): '+str(round(dataframe_mseed_final_duration.values.mean(),2)), fontsize=12, ha='right', va='center', transform=ax1.transAxes)

    # Set major ticks
    ax1.xaxis.set_major_locator(MultipleLocator(10))
    ax1.yaxis.set_major_locator(MultipleLocator(5))
    ax1.tick_params(axis='x', rotation=45)

    # Set minor ticks
    ax1.xaxis.set_minor_locator(MultipleLocator(1))
    ax1.yaxis.set_minor_locator(MultipleLocator(1))

    # Add a legend to the plot
    ax1.legend(loc='upper center')
    
    # -----
    
    if i == len(axes):
        ax.set_xlabel('Stream (nº)')
        ax1.set_xlabel('Stream (nº)')





filename_csv = '/media/sysop/14f7ead0-5dcb-4557-a139-55dbb404d11a/diogoloc/dados_posdoc/Gliders_DATA/data_glider_information_csv/metadados_glider_acustico_pmpas-bs.csv'


dataframe_csv = pd.read_csv(filename_csv,parse_dates=['time'])
dataframe_csv.sort_values(by='time')


df_csv = dataframe_csv.groupby("filename").agg(pd.Series.tolist)


df_csv


df_csv['filename_mseed'] = df_csv.index.str.replace('_rms_spl3.mat', '')


df_csv.sort_values(by='time')





merged_df_csv_mseed = df_csv.merge(dataframe_mseed_final, on='filename_mseed')


merged_df_csv_mseed['time_timestamp'] = merged_df_csv_mseed['time'].apply(lambda x: [pd.to_datetime(date).timestamp() for date in x])


merged_df_csv_mseed.sort_values(by='starttime')





def interp_dataframe_depth_lat_lon_time(filename_mseed,df=merged_df_csv_mseed,filenames_MSEED_lst=filenames_MSEED):
    new_df = df[df['filename_mseed'] == filename_mseed]
    # Dados de profundidade, latitude, longitude e tempo numérico
    profundidade = new_df['depth'].values[0]
    latitude = new_df['latitude'].values[0]
    longitude = new_df['longitude'].values[0]
    tempo_numerico = new_df['time_timestamp'].values[0]

    # Importar array de tempo interpolado
    for i in filenames_MSEED_lst:
        if filename_mseed in i:
            st = read(i,headonly=True)   
            tempo_interpolado_numerico = st[0].times('timestamp')
            tempo_interpolado = [k.datetime for k in st[0].times("utcdatetime")]
            tempo_obspy_times = st[0].times()

    # Interpolar os dados de profundidade usando numpy.interp
    profundidade_interpolada = np.interp(tempo_interpolado_numerico, tempo_numerico, profundidade)

    # Interpolar os dados de latitude usando numpy.interp
    latitude_interpolada = np.interp(tempo_interpolado_numerico, tempo_numerico, latitude)

    # Interpolar os dados de longitude usando numpy.interp
    longitude_interpolada = np.interp(tempo_interpolado_numerico, tempo_numerico, longitude)

    # Salvar os resultados
    df_interpolado = pd.DataFrame({'filename_mseed':filename_mseed+'.mseed',
                                   'Time_interp': tempo_interpolado, 
                                   'depth_interp': profundidade_interpolada, 
                                   'latitude_interp': latitude_interpolada, 
                                   'longitude_interp': longitude_interpolada})
    
    # Salvar o DataFrame em um arquivo Feather
    year = st[0].times("utcdatetime")[0].strftime('%Y')
    pasta_dia = st[0].times("utcdatetime")[0].strftime('%Y-%m-%d')
    output_folder_feather = FEATHER_OUTPUT+'/'+year+'/'+pasta_dia+'/'
    os.makedirs(output_folder_feather,exist_ok=True)
    df_interpolado.to_feather(output_folder_feather+filename_mseed+'.feather')


with Pool(processes=1) as p:
    max_ = len(merged_df_csv_mseed['filename_mseed'])
    with tqdm(total=max_) as pbar:
        for _ in p.imap_unordered(interp_dataframe_depth_lat_lon_time,merged_df_csv_mseed['filename_mseed']):
            pbar.update()






