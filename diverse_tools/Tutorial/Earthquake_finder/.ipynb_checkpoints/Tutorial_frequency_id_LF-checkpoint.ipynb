{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0288b9de",
   "metadata": {},
   "source": [
    "# Importando módulos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36e98d84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import obspy\n",
    "from obspy.taup import TauPyModel\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from obspy import read,UTCDateTime,Trace,read_inventory,read_events\n",
    "from obspy.io.sac.sactrace import SACTrace\n",
    "from obspy.imaging.beachball import beachball,beach\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy.signal.trigger import recursive_sta_lta,delayed_sta_lta,trigger_onset\n",
    "from obspy.signal.util import next_pow_2\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "import subprocess\n",
    "from sklearn import preprocessing\n",
    "import geopy.distance\n",
    "\n",
    "import pywt\n",
    "from matplotlib import mlab\n",
    "\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance,TimeSeriesResampler\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "\n",
    "#para plotar as figuras\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.transforms import offset_copy\n",
    "import matplotlib.ticker as ticker\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.dates as mdates\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.dates import YearLocator, MonthLocator, DayLocator, HourLocator, MinuteLocator, SecondLocator, DateFormatter\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter,FixedLocator,StrMethodFormatter\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from datetime import datetime,timedelta,date\n",
    "from tqdm import tqdm\n",
    "from kneed import KneeLocator\n",
    "\n",
    "from shapely.geometry.polygon import LinearRing\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "import cartopy.io.shapereader as shpreader\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.ticker import LongitudeFormatter,LatitudeFormatter\n",
    "import requests\n",
    "import csv\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4f9f8f",
   "metadata": {},
   "source": [
    "# Inputs e Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38736b57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FOLDER_OUTPUT = '/home/sysop/dados_posdoc/GLIDER_PETROBRAS/OUTPUT/'\n",
    "MSEED_INPUT = \"/home/sysop/dados_posdoc/GLIDER_PETROBRAS/DATA/\"\n",
    "METADATA_FILE = '/home/sysop/dados_posdoc/GLIDER_PETROBRAS/data_glider_information_csv/metadados_glider_acustico_pmpas-bs.csv'\n",
    "QUAKEXML_FOLDER = '/home/sysop/dados_posdoc/GLIDER_PETROBRAS/OUTPUT/EVENTS_FINDER/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067599c6-8fbc-4b3b-a3a4-d883f7513143",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd0ef00d-212a-443d-b6c8-d9cb2b8d4e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psd_cal(st,fmax=50.,winlen_HF=4.,winlen_LF=60.,overlap=0.5):\n",
    "    \n",
    "    '''\n",
    "    fmax: Maximum frequency for plot\n",
    "    winlen_HF: Window length for high-frequency spectrogram (in seconds)\n",
    "    winlen_LF: Window length for long-period spectrogram (in seconds)\n",
    "    overlap: Percentage of overlap (between 0 and 1) for spectrogram computation, if kind=='spec'\n",
    "    '''\n",
    "    \n",
    "    for tr in st.slide(window_length=winlen_LF,step=winlen_LF/2,include_partial_windows=False):   \n",
    "        \n",
    "        # The computation of the LF spectrograms with long time windows or even CWT\n",
    "        # can be REALLY slow, thus, decimate it to anything larger 2.5 Hz\n",
    "        st_LF = tr.copy()        \n",
    "        \n",
    "        # ----------------------\n",
    "        \n",
    "        # Decimate it to anything larger 2.5 Hz\n",
    "        st_LF.filter('lowpass', freq=0.95, corners=16)\n",
    "        \n",
    "        # For LF, 2 Hz is enough\n",
    "        st_LF.interpolate(sampling_rate=10,method='nearest')\n",
    "        \n",
    "        # ----------------------\n",
    "\n",
    "        st_HF = tr.copy()\n",
    "        \n",
    "        # ----------------------\n",
    "\n",
    "        winlen_LF == int(winlen_LF * st_LF.stats.sampling_rate)\n",
    "        winlen_HF == int(winlen_HF * st_HF.stats.sampling_rate)\n",
    "\n",
    "        # ----------------------\n",
    "\n",
    "        if st_LF.stats.sampling_rate > 10:\n",
    "            dec_fac = int(st_LF.stats.sampling_rate / 10)\n",
    "            st_LF.decimate(dec_fac)\n",
    "\n",
    "        # ----------------------\n",
    "\n",
    "        for st in [st_HF, st_LF]:\n",
    "            st.detrend()\n",
    "            st.filter('highpass', freq=1. / winlen_LF)\n",
    "\n",
    "        # ----------------------\n",
    "        fmin_LF = 2/winlen_LF\n",
    "        fmax_LF = 1\n",
    "        \n",
    "        fmin_HF = 0.8\n",
    "        fmax_HF = fmax\n",
    "        \n",
    "        fft_dic = {'data_FFT_HF':[],'freq_FFT_HF':[],'data_FFT_LF':[],'freq_FFT_LF':[],'starttime':[],'endtime':[]}\n",
    "\n",
    "        p_HF, f_HF = mlab.psd(preprocessing.normalize([st_HF.data])[0],Fs=st_HF.stats.sampling_rate,noverlap=int(winlen_LF*overlap))\n",
    "        bol_HF = np.array((f_HF >= fmin_HF * 0.9) & (f_HF <= fmax_HF))\n",
    "\n",
    "        p_LF, f_LF = mlab.psd(preprocessing.normalize([st_LF.data])[0],Fs=st_LF.stats.sampling_rate,noverlap=int(winlen_LF*overlap))\n",
    "        bol_LF = np.array((f_LF >= fmin_LF * 0.9) & (f_LF <= fmax_LF))\n",
    "\n",
    "        p_LF[bol_LF] = np.where(p_LF[bol_LF] == 0, 1e-10, p_LF[bol_LF])\n",
    "        p_HF[bol_HF] = np.where(p_HF[bol_HF] == 0, 1e-10, p_HF[bol_HF])\n",
    "\n",
    "        fft_dic['data_FFT_HF'] = 10 * np.log10(p_HF[bol_HF])\n",
    "        fft_dic['freq_FFT_HF'] = f_HF[bol_HF]\n",
    "        \n",
    "        fft_dic['data_FFT_LF'] = 10 * np.log10(p_LF[bol_LF])\n",
    "        fft_dic['freq_FFT_LF'] = f_LF[bol_LF]\n",
    "        \n",
    "        fft_dic['starttime'] =  tr.stats.starttime.datetime\n",
    "        fft_dic['endtime'] =  tr.stats.endtime.datetime\n",
    "\n",
    "        if not pd.isna(fft_dic) and not pd.isnull(fft_dic):\n",
    "            return fft_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebce2fe",
   "metadata": {},
   "source": [
    "# Lista com informações das Linhas de Fundeio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "355eb0e3-c145-4658-ac3f-7782fb579b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LF_lst = sorted(list(set([i.split('/')[8] for i in glob.glob(MSEED_INPUT+'*/*/*/*/'+'*LF.*')])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75182cc7-e74c-4715-8db7-b20ad869b72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F105A',\n",
       " 'F105B',\n",
       " 'F105C',\n",
       " 'F106A',\n",
       " 'F106B',\n",
       " 'F107A',\n",
       " 'F107B',\n",
       " 'F108A',\n",
       " 'F108B',\n",
       " 'F108C',\n",
       " 'F109A',\n",
       " 'F109B',\n",
       " 'F109C',\n",
       " 'F205B',\n",
       " 'F205C',\n",
       " 'F206C',\n",
       " 'F207A',\n",
       " 'F207B',\n",
       " 'F207C',\n",
       " 'F208A',\n",
       " 'F208B',\n",
       " 'F209B',\n",
       " 'F209C',\n",
       " 'F305A',\n",
       " 'F305B',\n",
       " 'F305C',\n",
       " 'F306A',\n",
       " 'F306B',\n",
       " 'F306C',\n",
       " 'F307A',\n",
       " 'F307B',\n",
       " 'F307C',\n",
       " 'F308A',\n",
       " 'F308B',\n",
       " 'F308C',\n",
       " 'F309A',\n",
       " 'F309B',\n",
       " 'F309C',\n",
       " 'F405A',\n",
       " 'F405B',\n",
       " 'F405C',\n",
       " 'F406B',\n",
       " 'F406C',\n",
       " 'F407B',\n",
       " 'F407C',\n",
       " 'F408A',\n",
       " 'F408C',\n",
       " 'F409B',\n",
       " 'F409C',\n",
       " 'F505A',\n",
       " 'F505B',\n",
       " 'F505C',\n",
       " 'F506A',\n",
       " 'F506B',\n",
       " 'F506C',\n",
       " 'F507A',\n",
       " 'F507C',\n",
       " 'F508A',\n",
       " 'F508C',\n",
       " 'F509A',\n",
       " 'F509C',\n",
       " 'F605A',\n",
       " 'F605B',\n",
       " 'F606A',\n",
       " 'F606B',\n",
       " 'F606C',\n",
       " 'F607A',\n",
       " 'F607C',\n",
       " 'F608A',\n",
       " 'F608B',\n",
       " 'F608C',\n",
       " 'F609A',\n",
       " 'F609B',\n",
       " 'F609C']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LF_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d422b198-0c2f-478a-9f8b-7457d1bb9e60",
   "metadata": {},
   "source": [
    "# Criando a identidade frequencial dos equipamentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd474a49-1674-4df8-971d-35aab5074051",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3393, 5)\n",
      "count                                                  3393\n",
      "unique                                                 3393\n",
      "top       [-56.23432438082444, -54.356041908463304, -53....\n",
      "freq                                                      1\n",
      "Name: data_FFT_HF, dtype: object\n",
      "(3393, 127, 1)\n",
      "[[[ -56.23432438]\n",
      "  [ -54.35604191]\n",
      "  [ -53.32673547]\n",
      "  ...\n",
      "  [ -77.0129466 ]\n",
      "  [ -77.8865038 ]\n",
      "  [ -81.36958556]]\n",
      "\n",
      " [[ -55.23887419]\n",
      "  [ -54.87492862]\n",
      "  [ -53.08496576]\n",
      "  ...\n",
      "  [ -82.40728783]\n",
      "  [ -83.16858324]\n",
      "  [ -85.9945868 ]]\n",
      "\n",
      " [[ -56.31328286]\n",
      "  [ -55.36021777]\n",
      "  [ -54.70919085]\n",
      "  ...\n",
      "  [ -85.96782261]\n",
      "  [ -86.0903253 ]\n",
      "  [ -88.69324148]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ -53.43768446]\n",
      "  [ -52.018499  ]\n",
      "  [ -50.96174295]\n",
      "  ...\n",
      "  [-100.84850533]\n",
      "  [-100.64375517]\n",
      "  [-103.6076446 ]]\n",
      "\n",
      " [[ -53.41090274]\n",
      "  [ -51.85480414]\n",
      "  [ -50.79042808]\n",
      "  ...\n",
      "  [-101.43782249]\n",
      "  [-101.75682548]\n",
      "  [-104.72240306]]\n",
      "\n",
      " [[ -53.4063206 ]\n",
      "  [ -51.9967924 ]\n",
      "  [ -50.94355464]\n",
      "  ...\n",
      "  [-102.65894536]\n",
      "  [-102.72347926]\n",
      "  [-105.4266634 ]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing LF data:  84%|███████████████████▎   | 62/74 [01:12<00:14,  1.17s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 158\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n_clusters \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m1\u001b[39m),total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m1\u001b[39m)),desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mElbow Method: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mseletected_STA,position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    157\u001b[0m     km \u001b[38;5;241m=\u001b[39m TimeSeriesKMeans(n_clusters\u001b[38;5;241m=\u001b[39mn_clusters, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m--> 158\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mkm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m     elbow_data\u001b[38;5;241m.\u001b[39mappend((n_clusters, km\u001b[38;5;241m.\u001b[39minertia_))\n\u001b[1;32m    161\u001b[0m k_range \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Programs/miniconda3/lib/python3.11/site-packages/tslearn/clustering/kmeans.py:854\u001b[0m, in \u001b[0;36mTimeSeriesKMeans.fit_predict\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit k-means clustering using X and then predict the closest cluster\u001b[39;00m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;124;03meach time series in X belongs to.\u001b[39;00m\n\u001b[1;32m    836\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;124;03m    Index of the cluster each sample belongs to.\u001b[39;00m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    853\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(X, allow_nd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 854\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlabels_\n",
      "File \u001b[0;32m~/Programs/miniconda3/lib/python3.11/site-packages/tslearn/clustering/kmeans.py:821\u001b[0m, in \u001b[0;36mTimeSeriesKMeans.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInit \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_successful \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    820\u001b[0m n_attempts \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 821\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_one_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minertia_ \u001b[38;5;241m<\u001b[39m min_inertia:\n\u001b[1;32m    823\u001b[0m     best_correct_centroids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcluster_centers_\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/Programs/miniconda3/lib/python3.11/site-packages/tslearn/clustering/kmeans.py:690\u001b[0m, in \u001b[0;36mTimeSeriesKMeans._fit_one_init\u001b[0;34m(self, X, x_squared_norms, rs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minertia_, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m --> \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 690\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_centroids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m numpy\u001b[38;5;241m.\u001b[39mabs(old_inertia \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minertia_) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol:\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Programs/miniconda3/lib/python3.11/site-packages/tslearn/clustering/kmeans.py:762\u001b[0m, in \u001b[0;36mTimeSeriesKMeans._update_centroids\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcluster_centers_[k] \u001b[38;5;241m=\u001b[39m softdtw_barycenter(\n\u001b[1;32m    756\u001b[0m         X\u001b[38;5;241m=\u001b[39mX[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_ \u001b[38;5;241m==\u001b[39m k],\n\u001b[1;32m    757\u001b[0m         max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter_barycenter,\n\u001b[1;32m    758\u001b[0m         init\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcluster_centers_[k],\n\u001b[1;32m    759\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmetric_params\n\u001b[1;32m    760\u001b[0m     )\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 762\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcluster_centers_[k] \u001b[38;5;241m=\u001b[39m \u001b[43meuclidean_barycenter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabels_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programs/miniconda3/lib/python3.11/site-packages/tslearn/barycenters/euclidean.py:42\u001b[0m, in \u001b[0;36meuclidean_barycenter\u001b[0;34m(X, weights)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meuclidean_barycenter\u001b[39m(X, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     10\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Standard Euclidean barycenter computed from a set of time series.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m           [4.5]])\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     X_ \u001b[38;5;241m=\u001b[39m \u001b[43mto_time_series_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     weights \u001b[38;5;241m=\u001b[39m _set_weights(weights, X_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m numpy\u001b[38;5;241m.\u001b[39maverage(X_, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39mweights)\n",
      "File \u001b[0;32m~/Programs/miniconda3/lib/python3.11/site-packages/tslearn/utils/utils.py:226\u001b[0m, in \u001b[0;36mto_time_series_dataset\u001b[0;34m(dataset, dtype, be)\u001b[0m\n\u001b[1;32m    223\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m [dataset]\n\u001b[1;32m    224\u001b[0m n_ts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataset)\n\u001b[1;32m    225\u001b[0m max_sz \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\n\u001b[0;32m--> 226\u001b[0m     \u001b[43m[\u001b[49m\u001b[43mts_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_time_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_nans\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbe\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    227\u001b[0m )\n\u001b[1;32m    228\u001b[0m d \u001b[38;5;241m=\u001b[39m be\u001b[38;5;241m.\u001b[39mshape(to_time_series(dataset[\u001b[38;5;241m0\u001b[39m], be\u001b[38;5;241m=\u001b[39mbe))[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    229\u001b[0m dataset_out \u001b[38;5;241m=\u001b[39m be\u001b[38;5;241m.\u001b[39mzeros((n_ts, max_sz, d), dtype\u001b[38;5;241m=\u001b[39mdtype) \u001b[38;5;241m+\u001b[39m be\u001b[38;5;241m.\u001b[39mnan\n",
      "File \u001b[0;32m~/Programs/miniconda3/lib/python3.11/site-packages/tslearn/utils/utils.py:226\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m [dataset]\n\u001b[1;32m    224\u001b[0m n_ts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataset)\n\u001b[1;32m    225\u001b[0m max_sz \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\n\u001b[0;32m--> 226\u001b[0m     [ts_size(\u001b[43mto_time_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_nans\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbe\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m ts \u001b[38;5;129;01min\u001b[39;00m dataset]\n\u001b[1;32m    227\u001b[0m )\n\u001b[1;32m    228\u001b[0m d \u001b[38;5;241m=\u001b[39m be\u001b[38;5;241m.\u001b[39mshape(to_time_series(dataset[\u001b[38;5;241m0\u001b[39m], be\u001b[38;5;241m=\u001b[39mbe))[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    229\u001b[0m dataset_out \u001b[38;5;241m=\u001b[39m be\u001b[38;5;241m.\u001b[39mzeros((n_ts, max_sz, d), dtype\u001b[38;5;241m=\u001b[39mdtype) \u001b[38;5;241m+\u001b[39m be\u001b[38;5;241m.\u001b[39mnan\n",
      "File \u001b[0;32m~/Programs/miniconda3/lib/python3.11/site-packages/tslearn/utils/utils.py:165\u001b[0m, in \u001b[0;36mto_time_series\u001b[0;34m(ts, remove_nans, be)\u001b[0m\n\u001b[1;32m    163\u001b[0m     ts_out \u001b[38;5;241m=\u001b[39m be\u001b[38;5;241m.\u001b[39mcast(ts_out, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remove_nans:\n\u001b[0;32m--> 165\u001b[0m     ts_out \u001b[38;5;241m=\u001b[39m ts_out[: \u001b[43mts_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mts_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbe\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ts_out\n",
      "File \u001b[0;32m~/Programs/miniconda3/lib/python3.11/site-packages/tslearn/utils/utils.py:445\u001b[0m, in \u001b[0;36mts_size\u001b[0;34m(ts, be)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mts_size\u001b[39m(ts, be\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    405\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns actual time series size.\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \n\u001b[1;32m    407\u001b[0m \u001b[38;5;124;03m    Final timesteps that have `NaN` values for all dimensions will be removed\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03m    3\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 445\u001b[0m     be \u001b[38;5;241m=\u001b[39m \u001b[43minstantiate_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m     ts_ \u001b[38;5;241m=\u001b[39m to_time_series(ts, be\u001b[38;5;241m=\u001b[39mbe)\n\u001b[1;32m    447\u001b[0m     sz \u001b[38;5;241m=\u001b[39m be\u001b[38;5;241m.\u001b[39mshape(ts_)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Programs/miniconda3/lib/python3.11/site-packages/tslearn/backend/backend.py:18\u001b[0m, in \u001b[0;36minstantiate_backend\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     13\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     14\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not use pytorch backend since torch is not installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m             )\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minstantiate_backend\u001b[39m(\u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     19\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Select backend.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m    Parameter\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m        The backend instance.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _draw_all_if_interactive at 0x7fc8fc198400> (for post_execute), with arguments args (),kwargs {}:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function flush_figures at 0x7fc83d224f40> (for post_execute), with arguments args (),kwargs {}:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seletected_STA in tqdm(LF_lst,desc='Processing LF data',total=len(LF_lst),position=0,leave=True):\n",
    "    if os.path.exists(FOLDER_OUTPUT+'FIGURAS/PSD/LF/'+seletected_STA+'/df_psd_LF_'+seletected_STA+'_KMeans.feather'):\n",
    "        pass\n",
    "    else:\n",
    "            \n",
    "        files_mseed_ev = sorted(glob.glob(MSEED_INPUT+'*/*/*/*/'+'*LF.'+seletected_STA+'*'+'..HHH.D.*'))\n",
    "        stream_mseed = [read(file) for file in files_mseed_ev]\n",
    "        \n",
    "        flat_list = [item for sublist in stream_mseed for item in sublist]\n",
    "    \n",
    "        # ========================================================================================================= #\n",
    "        \n",
    "        # --------------------------\n",
    "        # Calculando os PSDs\n",
    "        \n",
    "        df_results = []\n",
    "        with Pool(processes=20) as p:\n",
    "            max_ = len(flat_list)\n",
    "            with tqdm(total=max_,position=0,leave=False) as pbar:\n",
    "                for result in p.imap_unordered(psd_cal,flat_list):\n",
    "                    df_results.append(result)           \n",
    "                    pbar.update()\n",
    "    \n",
    "        # --------------------------\n",
    "        # Remove NaN and None values\n",
    "        df_results_clean = [x for x in df_results if not pd.isna(x)]\n",
    "    \n",
    "        # --------------------------\n",
    "        # Criando o Dataframe com os PSDs calculados\n",
    "        fft_data_df = pd.DataFrame(df_results_clean)\n",
    "        # Convert 'date' to datetime object, if not already}\n",
    "        fft_data_df['starttime'] = pd.to_datetime(fft_data_df['starttime'])\n",
    "        fft_data_df['endtime'] = pd.to_datetime(fft_data_df['endtime'])\n",
    "            \n",
    "        # --------------------------\n",
    "        # Agrupando o Dataframe com os PSDs calculados a cada 1 hora\n",
    "        df_grouped = fft_data_df.groupby(pd.Grouper(key='starttime', freq='1h')).mean()\n",
    "        # Drop rows with any NaN values\n",
    "        df_grouped = df_grouped.dropna()\n",
    "        \n",
    "        if not df_grouped.shape[0] > 10:\n",
    "            pass\n",
    "        else:\n",
    "        \n",
    "            ################################\n",
    "            ##### CREATING THE FIGURE ######\n",
    "            ################################\n",
    "            \n",
    "            # Locator: X & Y\n",
    "            majorX = MultipleLocator(5)\n",
    "            majorY = MultipleLocator(20)\n",
    "            \n",
    "            minorX = MultipleLocator(1)\n",
    "            minorY = MultipleLocator(10)\n",
    "            \n",
    "            fig_data = plt.figure(figsize=(20,10))\n",
    "            \n",
    "            # [left bottom width height]\n",
    "            w_total = 1\n",
    "            h_base = 0.13\n",
    "            w_base = 0.08\n",
    "            plot_ratio=0.3\n",
    "            \n",
    "            w_LF = w_total * plot_ratio\n",
    "            w_HF = w_total - w_LF\n",
    "\n",
    "            alpha = 0.75\n",
    "            lw = 0.1\n",
    "            \n",
    "            ax_psd_LF = fig_data.add_axes([w_base, h_base, w_LF, 0.7],label='PSD LF')\n",
    "            ax_psd_HF = fig_data.add_axes([w_base+plot_ratio, h_base,w_HF,0.7],label='PSD HF',sharey=ax_psd_LF)\n",
    "            #(left, bottom, width, height)\n",
    "\n",
    "            # Normalizing dates\n",
    "            date_nums = mdates.date2num(df_grouped['endtime'])\n",
    "            norm = plt.Normalize(vmin=min(date_nums), vmax=max(date_nums))  # Normaliza para o range das datas\n",
    "            cmap = plt.get_cmap(\"cividis\")\n",
    "            \n",
    "            # Plot PSD computed via both methods\n",
    "            for i in df_grouped.iterrows():\n",
    "                year_quarter = i[1]['endtime']\n",
    "                color = cmap(norm(mdates.date2num(year_quarter)))\n",
    "                ax_psd_LF.plot(i[1]['freq_FFT_LF'], i[1]['data_FFT_LF'], color=color, lw=lw, alpha=alpha)\n",
    "                ax_psd_HF.plot(i[1]['freq_FFT_HF'], i[1]['data_FFT_HF'], color=color, lw=lw, alpha=alpha)\n",
    "            \n",
    "            ax_psd_LF.plot(df_grouped['freq_FFT_LF'].mean(),df_grouped['data_FFT_LF'].mean(), color='k', lw=1)\n",
    "            ax_psd_HF.plot(df_grouped['freq_FFT_HF'].mean(),df_grouped['data_FFT_HF'].mean(), color='k', lw=1)\n",
    "            \n",
    "            # Set limits for x-axes\n",
    "            ax_psd_LF.set_xlim(0.01, 1)\n",
    "            ax_psd_HF.set_xlim(1, 50)\n",
    "        \n",
    "            # Set labels for axes\n",
    "            ax_psd_LF.set_ylabel('Spectral level (dB)')\n",
    "            ax_psd_LF.set_xlabel('Frequency (Hz)')\n",
    "        \n",
    "            ax_psd_HF.text(0.9, 0.9,'Total = '+str(df_grouped.shape[0]),fontweight='bold', fontsize=12, ha='center',va='center',transform=ax_psd_HF.transAxes)\n",
    "            ax_psd_HF.text(0.1, 0.9,seletected_STA,fontweight='bold', fontsize=15, ha='right',va='center',transform=ax_psd_HF.transAxes)\n",
    "            \n",
    "            # Set ticks and labels on both sides of the y-axis\n",
    "            ax_psd_LF.yaxis.set_tick_params(labelleft=True,labelright=False,left=True, right=True)  # Show labels on the right side\n",
    "            ax_psd_LF.spines['top'].set_linewidth(2)\n",
    "            ax_psd_LF.spines['right'].set_linewidth(2)\n",
    "            ax_psd_LF.spines['bottom'].set_linewidth(2)\n",
    "            ax_psd_LF.spines['left'].set_linewidth(2)\n",
    "            ax_psd_LF.xaxis.set_tick_params(width=2)\n",
    "            ax_psd_LF.yaxis.set_tick_params(width=2)\n",
    "        \n",
    "            ax_psd_LF.xaxis.set_major_locator(MultipleLocator(0.3))\n",
    "            ax_psd_LF.xaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "            ax_psd_LF.yaxis.set_major_locator(majorY)\n",
    "            ax_psd_LF.yaxis.set_minor_locator(minorY)\n",
    "        \n",
    "            # Set ticks and labels on both sides of the y-axis\n",
    "            ax_psd_HF.yaxis.set_tick_params(labelleft=False,labelright=True,left=True, right=True)  # Show labels on the right side\n",
    "            ax_psd_HF.spines['top'].set_linewidth(2)\n",
    "            ax_psd_HF.spines['right'].set_linewidth(2)\n",
    "            ax_psd_HF.spines['bottom'].set_linewidth(2)\n",
    "            ax_psd_HF.spines['left'].set_linewidth(2)\n",
    "            ax_psd_HF.xaxis.set_tick_params(width=2)\n",
    "            ax_psd_HF.yaxis.set_tick_params(width=2)\n",
    "            \n",
    "            ax_psd_HF.xaxis.set_major_locator(majorX)\n",
    "            ax_psd_HF.xaxis.set_minor_locator(minorX)\n",
    "            ax_psd_HF.yaxis.set_major_locator(majorY)\n",
    "            ax_psd_HF.yaxis.set_minor_locator(minorY)\n",
    "                \n",
    "            # Create a scalar mappable for the colorbar\n",
    "            sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=mdates.date2num(df_grouped['endtime'].values[0]), vmax=mdates.date2num(df_grouped['endtime'].values[-1])))\n",
    "            \n",
    "            # Create the colorbar\n",
    "            cbar = fig_data.colorbar(sm, ax=[ax_psd_LF, ax_psd_HF], orientation='vertical')\n",
    "            cbar.set_label('Days of the year')\n",
    "            \n",
    "            # Set the ticks and tick labels for the colorbar\n",
    "            ticks = np.linspace(cbar.vmin, cbar.vmax, 6)  # Gera ticks uniformemente espaçados\n",
    "            cbar.set_ticks(ticks)\n",
    "            cbar.ax.yaxis.set_major_formatter(mdates.DateFormatter('%d/%m/%Y'))\n",
    "            \n",
    "            os.makedirs(FOLDER_OUTPUT+'FIGURAS/PSD/LF/'+seletected_STA+'/',exist_ok=True)\n",
    "            fig_data.savefig(FOLDER_OUTPUT+'FIGURAS/PSD/LF/'+seletected_STA+'/LF_'+seletected_STA+'_Data.png',pad_inches=0.02,dpi=200)\n",
    "            \n",
    "            # ========================================================================================================= #\n",
    "            print(df_grouped.shape)\n",
    "            print(df_grouped['data_FFT_HF'].describe())\n",
    "\n",
    "            # ------------------------------------\n",
    "            # Adjusting arrays to KMeans procedure\n",
    "            X_train = TimeSeriesResampler(sz=len(df_grouped['data_FFT_HF'].values[0])).fit_transform(df_grouped['data_FFT_HF'].values)\n",
    "            print(X_train.shape)\n",
    "            print(X_train)\n",
    "            # ------------------------------------\n",
    "            # Elbow KMeans estimation\n",
    "            elbow_data = []\n",
    "            for n_clusters in tqdm(range(1,10,1),total=len(range(1,10,1)),desc='Elbow Method: '+seletected_STA,position=0,leave=False):\n",
    "            \n",
    "                km = TimeSeriesKMeans(n_clusters=n_clusters, verbose=False, random_state=0,n_jobs=20)\n",
    "                y_pred = km.fit_predict(X_train)\n",
    "                elbow_data.append((n_clusters, km.inertia_))\n",
    "        \n",
    "            k_range = []\n",
    "            inertias = []\n",
    "            for elb in elbow_data:\n",
    "                k_range.append(elb[0])\n",
    "                inertias.append(elb[1])\n",
    "\n",
    "            # ------------------------------------    \n",
    "            # Elbow KMeans estimation\n",
    "            kn = KneeLocator(k_range, inertias,S=2, curve='convex', direction='decreasing')\n",
    "            elbow_point = kn.knee\n",
    "            \n",
    "            # ------------------------------------\n",
    "            # Elbow KMeans plot\n",
    "            \n",
    "            fig_elb, ax_elb = plt.subplots(figsize=(10,5))\n",
    "            \n",
    "            ax_elb.annotate(str(elbow_point), xy=(elbow_point,inertias[k_range.index(elbow_point)]), xytext=(elbow_point+(elbow_point*0.5),inertias[k_range.index(elbow_point)]+(inertias[k_range.index(elbow_point)]*0.5)),arrowprops=dict(arrowstyle='<-',linewidth=0.25,color='black'))\n",
    "            ax_elb.scatter(elbow_point,inertias[k_range.index(elbow_point)],color='k', marker='X',s=100)\n",
    "            ax_elb.plot(k_range,inertias,color='grey', marker='o', linestyle='dashed',linewidth=2, markersize=5,zorder=-1)\n",
    "            ax_elb.text(0.85, 0.9,seletected_STA,fontweight='bold', fontsize=25, ha='right',va='center',transform=ax_elb.transAxes)\n",
    "            \n",
    "            # Set ticks and labels on both sides of the y-axis\n",
    "            ax_elb.set_xlim(0,10)\n",
    "            ax_elb.set_ylabel('Inertias')\n",
    "            ax_elb.set_xlabel('Values of K')\n",
    "            fig_elb.savefig(FOLDER_OUTPUT+'FIGURAS/PSD/LF/'+seletected_STA+'/LF_'+seletected_STA+'_Elbow_plot.png',pad_inches=0.02,dpi=200)\n",
    "\n",
    "            # ------------------------------------\n",
    "            # Euclidean k-means\n",
    "           \n",
    "            n_clu = elbow_point\n",
    "            km = TimeSeriesKMeans(n_clusters=n_clu, verbose=False, random_state=0)\n",
    "            y_pred = km.fit_predict(X_train)\n",
    "            \n",
    "            df_grouped['k-means'] = y_pred\n",
    "            \n",
    "            ################################\n",
    "            ##### CREATING THE FIGURE ######\n",
    "            ################################\n",
    "            \n",
    "            fig = plt.figure(figsize=(20,10))\n",
    "            gs = gridspec.GridSpec(3, n_clu)\n",
    "            \n",
    "            ax_psd_HF = fig.add_subplot(gs[:2, :])\n",
    "               \n",
    "            # Plot PSD computed via both methods\n",
    "            for i in df_grouped.iterrows():\n",
    "                year_quarter = i[1]['endtime']\n",
    "                color = cmap(norm(mdates.date2num(year_quarter)))\n",
    "                ax_psd_HF.plot(i[1]['freq_FFT_HF'], i[1]['data_FFT_HF'], color=color, lw=lw, alpha=alpha)\n",
    "            \n",
    "            ax_psd_HF.plot(df_grouped['freq_FFT_HF'].mean(),df_grouped['data_FFT_HF'].mean(), color='k', lw=2)\n",
    "            ax_psd_HF.text(0.9, 0.9,'Total = '+str(df_grouped.shape[0]),fontweight='bold', fontsize=12, ha='center',va='center',transform=ax_psd_HF.transAxes)\n",
    "            ax_psd_HF.text(0.1, 0.9,seletected_STA,fontweight='bold', fontsize=15, ha='right',va='center',transform=ax_psd_HF.transAxes)\n",
    "            \n",
    "            ax_psd_HF.set_ylabel('Spectral level (dB)')\n",
    "            \n",
    "            # Set limits for x-axes\n",
    "            ax_psd_HF.set_xlim(1, 50)\n",
    "            ax_psd_HF.set_ylim(-120,-20)\n",
    "            \n",
    "            # Set ticks and labels on both sides of the y-axis\n",
    "            ax_psd_HF.yaxis.set_tick_params(labelright=True,left=True, right=True)  # Show labels on the right side\n",
    "            ax_psd_HF.spines['top'].set_linewidth(2)\n",
    "            ax_psd_HF.spines['right'].set_linewidth(2)\n",
    "            ax_psd_HF.spines['bottom'].set_linewidth(2)\n",
    "            ax_psd_HF.spines['left'].set_linewidth(2)\n",
    "            ax_psd_HF.xaxis.set_tick_params(width=2)\n",
    "            ax_psd_HF.yaxis.set_tick_params(width=2)\n",
    "            \n",
    "            ax_psd_HF.xaxis.set_major_locator(majorX)\n",
    "            ax_psd_HF.xaxis.set_minor_locator(minorX)\n",
    "            ax_psd_HF.yaxis.set_major_locator(majorY)\n",
    "            ax_psd_HF.yaxis.set_minor_locator(minorY)\n",
    "            \n",
    "            # =======================================================================================================================================\n",
    "            \n",
    "            # Get unique k-means\n",
    "            unique_k_means = sorted(df_grouped['k-means'].unique())\n",
    "            \n",
    "            for k in unique_k_means:\n",
    "                ax = fig.add_subplot(gs[2, k])\n",
    "            \n",
    "                df_k = df_grouped[df_grouped['k-means'] == k]\n",
    "            \n",
    "                # Plot PSD computed via both methods\n",
    "                for i in df_k.iterrows():\n",
    "                    year_quarter = i[1]['endtime']\n",
    "                    color = cmap(norm(mdates.date2num(year_quarter)))\n",
    "                    ax.plot(i[1]['freq_FFT_HF'], i[1]['data_FFT_HF'], color=color, lw=lw, alpha=alpha)\n",
    "                ax.plot(df_k['freq_FFT_HF'].mean(),df_k['data_FFT_HF'].mean(), color='k', lw=2)\n",
    "                ax.text(0.5, 0.8,'Cluster %d' % (k + 1)+'\\n(n='+str(df_k.shape[0])+')',fontweight='bold', fontsize=12, ha='center',transform=ax.transAxes)\n",
    "            \n",
    "                ax.set_xlabel('Frequency (Hz)')\n",
    "                ax.set_ylim(-120,-20)\n",
    "                ax.set_xlim(1, 50)\n",
    "            \n",
    "                ax.spines['top'].set_linewidth(2)\n",
    "                ax.spines['right'].set_linewidth(2)\n",
    "                ax.spines['bottom'].set_linewidth(2)\n",
    "                ax.spines['left'].set_linewidth(2)\n",
    "                ax.xaxis.set_tick_params(width=2)\n",
    "                ax.yaxis.set_tick_params(width=2)  \n",
    "            \n",
    "                ax.xaxis.set_major_locator(majorX)\n",
    "                ax.xaxis.set_minor_locator(minorX)\n",
    "                ax.yaxis.set_major_locator(majorY)\n",
    "                ax.yaxis.set_minor_locator(minorY)\n",
    "                ax.yaxis.set_tick_params(labelright=False,labelleft=False,left=True, right=True)  # Show labels on the right side\n",
    "            \n",
    "                if k == unique_k_means[0]:\n",
    "                    ax.yaxis.set_tick_params(labelright=False,labelleft=True,left=True, right=True)  # Show labels on the right side\n",
    "                    ax.set_ylabel('Spectral level (dB)')\n",
    "            \n",
    "                if k == unique_k_means[-1]:\n",
    "                    ax.yaxis.set_tick_params(labelright=True,labelleft=False,left=True, right=True)  # Show labels on the right side\n",
    "            \n",
    "            # Create a color bar\n",
    "            # Create a scalar mappable for the colorbar\n",
    "            sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=mdates.date2num(df_grouped['endtime'].values[0]), vmax=mdates.date2num(df_grouped['endtime'].values[-1])))\n",
    "            \n",
    "            # Create the colorbar\n",
    "            cbar = fig.colorbar(sm,ax=ax_psd_HF,orientation='vertical')\n",
    "            cbar.set_label('Days of the year')\n",
    "            \n",
    "            # Set the ticks and tick labels for the colorbar\n",
    "            ticks = np.linspace(cbar.vmin, cbar.vmax, 6)  # Gera ticks uniformemente espaçados\n",
    "            cbar.set_ticks(ticks)\n",
    "            cbar.ax.yaxis.set_major_formatter(mdates.DateFormatter('%d/%m/%Y'))\n",
    "\n",
    "            fig.savefig(FOLDER_OUTPUT+'FIGURAS/PSD/LF/'+seletected_STA+'/LF_'+seletected_STA+'_KMeans.png',pad_inches=0.02,dpi=200)\n",
    "        \n",
    "            # =======================================================================================================================================\n",
    "            # Saving \n",
    "            # =======================================================================================================================================\n",
    "            df_grouped.to_feather(FOLDER_OUTPUT+'FIGURAS/PSD/LF/'+seletected_STA+'/df_psd_LF_'+seletected_STA+'_KMeans.feather') \n",
    "        \n",
    "            # ----------------------------------------------------------------------------------------------------------\n",
    "            # Close the figure after savig \n",
    "            # ----------------------------------------------------------------------------------------------------------                             \n",
    "                                            \n",
    "            plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a31c60d-5c31-4a78-963c-83c68e9255ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
