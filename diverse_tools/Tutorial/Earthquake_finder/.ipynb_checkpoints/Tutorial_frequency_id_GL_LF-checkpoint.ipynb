{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0288b9de",
   "metadata": {},
   "source": [
    "# Importando módulos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36e98d84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import obspy\n",
    "from obspy.taup import TauPyModel\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from obspy import read,UTCDateTime,Trace,read_inventory,read_events\n",
    "from obspy.io.sac.sactrace import SACTrace\n",
    "from obspy.imaging.beachball import beachball,beach\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy.signal.trigger import recursive_sta_lta,delayed_sta_lta,trigger_onset\n",
    "from obspy.signal.util import next_pow_2\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "import subprocess\n",
    "from sklearn import preprocessing\n",
    "import geopy.distance\n",
    "\n",
    "import pywt\n",
    "from matplotlib import mlab\n",
    "\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance,TimeSeriesResampler\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "\n",
    "#para plotar as figuras\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.transforms import offset_copy\n",
    "import matplotlib.ticker as ticker\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.dates as mdates\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.dates import YearLocator, MonthLocator, DayLocator, HourLocator, MinuteLocator, SecondLocator, DateFormatter\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter,FixedLocator,StrMethodFormatter\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from datetime import datetime,timedelta,date\n",
    "from tqdm import tqdm\n",
    "from kneed import KneeLocator\n",
    "\n",
    "from shapely.geometry.polygon import LinearRing\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "import cartopy.io.shapereader as shpreader\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.ticker import LongitudeFormatter,LatitudeFormatter\n",
    "import requests\n",
    "import csv\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4f9f8f",
   "metadata": {},
   "source": [
    "# Inputs e Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38736b57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FOLDER_OUTPUT = '/home/sysop/dados_posdoc/GLIDER_PETROBRAS/OUTPUT/'\n",
    "MSEED_INPUT = \"/home/sysop/dados_posdoc/GLIDER_PETROBRAS/DATA/\"\n",
    "METADATA_FILE = '/home/sysop/dados_posdoc/GLIDER_PETROBRAS/data_glider_information_csv/metadados_glider_acustico_pmpas-bs.csv'\n",
    "QUAKEXML_FOLDER = '/home/sysop/dados_posdoc/GLIDER_PETROBRAS/OUTPUT/EVENTS_FINDER/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebce2fe",
   "metadata": {},
   "source": [
    "# Lista com informações das PSD calculadas para os Gliders e a para as Linhas de Fundeio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "355eb0e3-c145-4658-ac3f-7782fb579b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LF_lst = sorted(glob.glob(FOLDER_OUTPUT+'FIGURAS/PSD/*/*/df_psd_LF_*_KMeans.feather'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75182cc7-e74c-4715-8db7-b20ad869b72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GL_lst = sorted(glob.glob(FOLDER_OUTPUT+'FIGURAS/PSD/*/*/df_psd_GL_*_KMeans.feather'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d422b198-0c2f-478a-9f8b-7457d1bb9e60",
   "metadata": {},
   "source": [
    "# Lendo a identidade frequencial calculada dos equipamentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2efdc446-a195-4b2d-b52d-5b3a5173790a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'The grouper name k-means is not found'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m col_w \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_FFT_HF\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfreq_FFT_HF\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m df_grouped \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol_w\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGrouper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mk-means\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mGL_lst_df\u001b[49m\u001b[43m]\u001b[49m \n",
      "Cell \u001b[0;32mIn[29], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m col_w \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_FFT_HF\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfreq_FFT_HF\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m df_grouped \u001b[38;5;241m=\u001b[39m [\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol_w\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGrouper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mk-means\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m GL_lst_df] \n",
      "File \u001b[0;32m~/Programs/miniconda3/lib/python3.11/site-packages/pandas/core/frame.py:9156\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   9153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   9154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 9156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   9157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9159\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9162\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9166\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programs/miniconda3/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1329\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1329\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1337\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[0;32m~/Programs/miniconda3/lib/python3.11/site-packages/pandas/core/groupby/grouper.py:929\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;66;03m# a passed-in Grouper, directly convert\u001b[39;00m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Grouper):\n\u001b[0;32m--> 929\u001b[0m     grouper, obj \u001b[38;5;241m=\u001b[39m \u001b[43mkey\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_grouper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    931\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m grouper, \u001b[38;5;28mfrozenset\u001b[39m(), obj\n",
      "File \u001b[0;32m~/Programs/miniconda3/lib/python3.11/site-packages/pandas/core/groupby/grouper.py:314\u001b[0m, in \u001b[0;36mGrouper._get_grouper\u001b[0;34m(self, obj, validate)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_grouper\u001b[39m(\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28mself\u001b[39m, obj: NDFrameT, validate: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    302\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[ops\u001b[38;5;241m.\u001b[39mBaseGrouper, NDFrameT]:\n\u001b[1;32m    303\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;124;03m    a tuple of grouper, obj (possibly sorted)\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m     obj, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_grouper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     grouper, _, obj \u001b[38;5;241m=\u001b[39m get_grouper(\n\u001b[1;32m    316\u001b[0m         obj,\n\u001b[1;32m    317\u001b[0m         [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    322\u001b[0m         dropna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna,\n\u001b[1;32m    323\u001b[0m     )\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;66;03m# Without setting this, subsequent lookups to .groups raise\u001b[39;00m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type \"BaseGrouper\",\u001b[39;00m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;66;03m# variable has type \"None\")\u001b[39;00m\n",
      "File \u001b[0;32m~/Programs/miniconda3/lib/python3.11/site-packages/pandas/core/groupby/grouper.py:380\u001b[0m, in \u001b[0;36mGrouper._set_grouper\u001b[0;34m(self, obj, sort, gpr_index)\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    379\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_info_axis:\n\u001b[0;32m--> 380\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe grouper name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    381\u001b[0m         ax \u001b[38;5;241m=\u001b[39m Index(obj[key], name\u001b[38;5;241m=\u001b[39mkey)\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'The grouper name k-means is not found'"
     ]
    }
   ],
   "source": [
    "col_w = ['data_FFT_HF', 'freq_FFT_HF']\n",
    "df_grouped = []\n",
    "for df_GL in GL_lst:\n",
    "\n",
    "    df_GL_dic = {'data_FFT_HF':[],'freq_FFT_HF':[],'station':[]}\n",
    "\n",
    "    df_GL_dic['data_FFT_HF'] = \n",
    "    \n",
    "    df_GL_dic['freq_FFT_HF'] = \n",
    "    \n",
    "    df_GL_dic['station'] = GL_lst[0].split('/')[-2]\n",
    "\n",
    "    df_grouped.append(df_GL_dic)\n",
    "    \n",
    "    \n",
    "    df_grouped = [a[col_w].groupby(pd.Grouper(key='k-means')).mean() for a in GL_lst_df] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a274efd-825d-4073-b007-0f118f9db888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_FFT_HF</th>\n",
       "      <th>freq_FFT_HF</th>\n",
       "      <th>data_FFT_LF</th>\n",
       "      <th>freq_FFT_LF</th>\n",
       "      <th>endtime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k-means</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-64.01116475827438, -57.62650443103836, -53.1...</td>\n",
       "      <td>[0.78125, 1.171875, 1.5625, 1.953125, 2.34375,...</td>\n",
       "      <td>[-33.5468241417991, -41.824411636762804, -48.3...</td>\n",
       "      <td>[0.0390625, 0.078125, 0.1171875, 0.15625, 0.19...</td>\n",
       "      <td>2015-11-21 13:16:01.047956224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-66.35223866281821, -59.94501668544327, -55.1...</td>\n",
       "      <td>[0.78125, 1.171875, 1.5625, 1.953125, 2.34375,...</td>\n",
       "      <td>[-29.849769625364704, -37.59399488946297, -42....</td>\n",
       "      <td>[0.0390625, 0.078125, 0.1171875, 0.15625, 0.19...</td>\n",
       "      <td>2015-11-24 17:54:19.209640960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-66.6781770961131, -60.90011962814612, -56.47...</td>\n",
       "      <td>[0.78125, 1.171875, 1.5625, 1.953125, 2.34375,...</td>\n",
       "      <td>[-28.256833888844525, -34.13631096812783, -37....</td>\n",
       "      <td>[0.0390625, 0.078125, 0.1171875, 0.15625, 0.19...</td>\n",
       "      <td>2015-11-28 08:29:48.806049792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-42.65674747489776, -40.74374033000317, -41.7...</td>\n",
       "      <td>[0.78125, 1.171875, 1.5625, 1.953125, 2.34375,...</td>\n",
       "      <td>[-55.74595718605506, -63.13354972890846, -69.7...</td>\n",
       "      <td>[0.0390625, 0.078125, 0.1171875, 0.15625, 0.19...</td>\n",
       "      <td>2015-11-25 17:25:32.285714432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               data_FFT_HF  \\\n",
       "k-means                                                      \n",
       "0        [-64.01116475827438, -57.62650443103836, -53.1...   \n",
       "1        [-66.35223866281821, -59.94501668544327, -55.1...   \n",
       "3        [-66.6781770961131, -60.90011962814612, -56.47...   \n",
       "2        [-42.65674747489776, -40.74374033000317, -41.7...   \n",
       "\n",
       "                                               freq_FFT_HF  \\\n",
       "k-means                                                      \n",
       "0        [0.78125, 1.171875, 1.5625, 1.953125, 2.34375,...   \n",
       "1        [0.78125, 1.171875, 1.5625, 1.953125, 2.34375,...   \n",
       "3        [0.78125, 1.171875, 1.5625, 1.953125, 2.34375,...   \n",
       "2        [0.78125, 1.171875, 1.5625, 1.953125, 2.34375,...   \n",
       "\n",
       "                                               data_FFT_LF  \\\n",
       "k-means                                                      \n",
       "0        [-33.5468241417991, -41.824411636762804, -48.3...   \n",
       "1        [-29.849769625364704, -37.59399488946297, -42....   \n",
       "3        [-28.256833888844525, -34.13631096812783, -37....   \n",
       "2        [-55.74595718605506, -63.13354972890846, -69.7...   \n",
       "\n",
       "                                               freq_FFT_LF  \\\n",
       "k-means                                                      \n",
       "0        [0.0390625, 0.078125, 0.1171875, 0.15625, 0.19...   \n",
       "1        [0.0390625, 0.078125, 0.1171875, 0.15625, 0.19...   \n",
       "3        [0.0390625, 0.078125, 0.1171875, 0.15625, 0.19...   \n",
       "2        [0.0390625, 0.078125, 0.1171875, 0.15625, 0.19...   \n",
       "\n",
       "                              endtime  \n",
       "k-means                                \n",
       "0       2015-11-21 13:16:01.047956224  \n",
       "1       2015-11-24 17:54:19.209640960  \n",
       "3       2015-11-28 08:29:48.806049792  \n",
       "2       2015-11-25 17:25:32.285714432  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd474a49-1674-4df8-971d-35aab5074051",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing LF data: 100%|█████████████████████| 74/74 [1:23:10<00:00, 67.44s/it]\n"
     ]
    }
   ],
   "source": [
    "for seletected_STA in tqdm(LF_lst,desc='Processing LF data',total=len(LF_lst),position=0,leave=True):\n",
    "    if os.path.exists(FOLDER_OUTPUT+'FIGURAS/PSD/LF/'+seletected_STA+'/df_psd_LF_'+seletected_STA+'_KMeans.feather'):\n",
    "        pass\n",
    "    else:\n",
    "            \n",
    "        files_mseed_ev = sorted(glob.glob(MSEED_INPUT+'*/*/*/*/'+'*LF.'+seletected_STA+'*'+'..HHH.D.*'))\n",
    "        stream_mseed = [read(file) for file in files_mseed_ev]\n",
    "        \n",
    "        flat_list = [item for sublist in stream_mseed for item in sublist]\n",
    "    \n",
    "        # ========================================================================================================= #\n",
    "        \n",
    "        # --------------------------\n",
    "        # Calculando os PSDs\n",
    "        \n",
    "        df_results = []\n",
    "        with Pool(processes=20) as p:\n",
    "            max_ = len(flat_list)\n",
    "            with tqdm(total=max_,position=0,leave=False) as pbar:\n",
    "                for result in p.imap_unordered(psd_cal,flat_list):\n",
    "                    df_results.append(result)           \n",
    "                    pbar.update()\n",
    "    \n",
    "        # --------------------------\n",
    "        # Remove NaN and None values\n",
    "        df_results_clean = [x for x in df_results if not pd.isna(x)]\n",
    "    \n",
    "        # --------------------------\n",
    "        # Criando o Dataframe com os PSDs calculados\n",
    "        fft_data_df = pd.DataFrame(df_results_clean)\n",
    "        # Convert 'date' to datetime object, if not already}\n",
    "        fft_data_df['starttime'] = pd.to_datetime(fft_data_df['starttime'])\n",
    "        fft_data_df['endtime'] = pd.to_datetime(fft_data_df['endtime'])\n",
    "            \n",
    "        # --------------------------\n",
    "        # Agrupando o Dataframe com os PSDs calculados a cada 1 hora\n",
    "        df_grouped = fft_data_df.groupby(pd.Grouper(key='starttime', freq='1h')).mean()\n",
    "        # Drop rows with any NaN values\n",
    "        df_grouped = df_grouped.dropna()\n",
    "        \n",
    "        if not df_grouped.shape[0] > 10:\n",
    "            pass\n",
    "        else:\n",
    "        \n",
    "            ################################\n",
    "            ##### CREATING THE FIGURE ######\n",
    "            ################################\n",
    "            \n",
    "            # Locator: X & Y\n",
    "            majorX = MultipleLocator(5)\n",
    "            majorY = MultipleLocator(20)\n",
    "            \n",
    "            minorX = MultipleLocator(1)\n",
    "            minorY = MultipleLocator(10)\n",
    "            \n",
    "            fig_data = plt.figure(figsize=(20,10))\n",
    "            \n",
    "            # [left bottom width height]\n",
    "            w_total = 1\n",
    "            h_base = 0.13\n",
    "            w_base = 0.08\n",
    "            plot_ratio=0.3\n",
    "            \n",
    "            w_LF = w_total * plot_ratio\n",
    "            w_HF = w_total - w_LF\n",
    "\n",
    "            alpha = 0.75\n",
    "            lw = 0.1\n",
    "            \n",
    "            ax_psd_LF = fig_data.add_axes([w_base, h_base, w_LF, 0.7],label='PSD LF')\n",
    "            ax_psd_HF = fig_data.add_axes([w_base+plot_ratio, h_base,w_HF,0.7],label='PSD HF',sharey=ax_psd_LF)\n",
    "            #(left, bottom, width, height)\n",
    "\n",
    "            # Normalizing dates\n",
    "            date_nums = mdates.date2num(df_grouped['endtime'])\n",
    "            norm = plt.Normalize(vmin=min(date_nums), vmax=max(date_nums))  # Normaliza para o range das datas\n",
    "            cmap = plt.get_cmap(\"cividis\")\n",
    "            \n",
    "            # Plot PSD computed via both methods\n",
    "            for i in df_grouped.iterrows():\n",
    "                year_quarter = i[1]['endtime']\n",
    "                color = cmap(norm(mdates.date2num(year_quarter)))\n",
    "                ax_psd_LF.plot(i[1]['freq_FFT_LF'], i[1]['data_FFT_LF'], color=color, lw=lw, alpha=alpha)\n",
    "                ax_psd_HF.plot(i[1]['freq_FFT_HF'], i[1]['data_FFT_HF'], color=color, lw=lw, alpha=alpha)\n",
    "            \n",
    "            ax_psd_LF.plot(df_grouped['freq_FFT_LF'].mean(),df_grouped['data_FFT_LF'].mean(), color='k', lw=1)\n",
    "            ax_psd_HF.plot(df_grouped['freq_FFT_HF'].mean(),df_grouped['data_FFT_HF'].mean(), color='k', lw=1)\n",
    "            \n",
    "            # Set limits for x-axes\n",
    "            ax_psd_LF.set_xlim(0.01, 1)\n",
    "            ax_psd_HF.set_xlim(1, 50)\n",
    "        \n",
    "            # Set labels for axes\n",
    "            ax_psd_LF.set_ylabel('Spectral level (dB)')\n",
    "            ax_psd_LF.set_xlabel('Frequency (Hz)')\n",
    "        \n",
    "            ax_psd_HF.text(0.9, 0.9,'Total = '+str(df_grouped.shape[0]),fontweight='bold', fontsize=12, ha='center',va='center',transform=ax_psd_HF.transAxes)\n",
    "            ax_psd_HF.text(0.1, 0.9,seletected_STA,fontweight='bold', fontsize=15, ha='right',va='center',transform=ax_psd_HF.transAxes)\n",
    "            \n",
    "            # Set ticks and labels on both sides of the y-axis\n",
    "            ax_psd_LF.yaxis.set_tick_params(labelleft=True,labelright=False,left=True, right=True)  # Show labels on the right side\n",
    "            ax_psd_LF.spines['top'].set_linewidth(2)\n",
    "            ax_psd_LF.spines['right'].set_linewidth(2)\n",
    "            ax_psd_LF.spines['bottom'].set_linewidth(2)\n",
    "            ax_psd_LF.spines['left'].set_linewidth(2)\n",
    "            ax_psd_LF.xaxis.set_tick_params(width=2)\n",
    "            ax_psd_LF.yaxis.set_tick_params(width=2)\n",
    "        \n",
    "            ax_psd_LF.xaxis.set_major_locator(MultipleLocator(0.3))\n",
    "            ax_psd_LF.xaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "            ax_psd_LF.yaxis.set_major_locator(majorY)\n",
    "            ax_psd_LF.yaxis.set_minor_locator(minorY)\n",
    "        \n",
    "            # Set ticks and labels on both sides of the y-axis\n",
    "            ax_psd_HF.yaxis.set_tick_params(labelleft=False,labelright=True,left=True, right=True)  # Show labels on the right side\n",
    "            ax_psd_HF.spines['top'].set_linewidth(2)\n",
    "            ax_psd_HF.spines['right'].set_linewidth(2)\n",
    "            ax_psd_HF.spines['bottom'].set_linewidth(2)\n",
    "            ax_psd_HF.spines['left'].set_linewidth(2)\n",
    "            ax_psd_HF.xaxis.set_tick_params(width=2)\n",
    "            ax_psd_HF.yaxis.set_tick_params(width=2)\n",
    "            \n",
    "            ax_psd_HF.xaxis.set_major_locator(majorX)\n",
    "            ax_psd_HF.xaxis.set_minor_locator(minorX)\n",
    "            ax_psd_HF.yaxis.set_major_locator(majorY)\n",
    "            ax_psd_HF.yaxis.set_minor_locator(minorY)\n",
    "                \n",
    "            # Create a scalar mappable for the colorbar\n",
    "            sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=mdates.date2num(df_grouped['endtime'].values[0]), vmax=mdates.date2num(df_grouped['endtime'].values[-1])))\n",
    "            \n",
    "            # Create the colorbar\n",
    "            cbar = fig_data.colorbar(sm, ax=[ax_psd_LF, ax_psd_HF], orientation='vertical')\n",
    "            cbar.set_label('Days of the year')\n",
    "            \n",
    "            # Set the ticks and tick labels for the colorbar\n",
    "            ticks = np.linspace(cbar.vmin, cbar.vmax, 6)  # Gera ticks uniformemente espaçados\n",
    "            cbar.set_ticks(ticks)\n",
    "            cbar.ax.yaxis.set_major_formatter(mdates.DateFormatter('%d/%m/%Y'))\n",
    "            \n",
    "            os.makedirs(FOLDER_OUTPUT+'FIGURAS/PSD/LF/'+seletected_STA+'/',exist_ok=True)\n",
    "            fig_data.savefig(FOLDER_OUTPUT+'FIGURAS/PSD/LF/'+seletected_STA+'/LF_'+seletected_STA+'_Data.png',pad_inches=0.02,dpi=200)\n",
    "            \n",
    "            # ========================================================================================================= #\n",
    "\n",
    "            # ------------------------------------\n",
    "            # Adjusting arrays to KMeans procedure\n",
    "            X_train = TimeSeriesResampler(sz=len(df_grouped['data_FFT_HF'].values[0])).fit_transform(df_grouped['data_FFT_HF'].values)\n",
    "\n",
    "            # ------------------------------------\n",
    "            # Elbow KMeans estimation\n",
    "            elbow_data = []\n",
    "            for n_clusters in tqdm(range(1,10,1),total=len(range(1,10,1)),desc='Elbow Method: '+seletected_STA,position=0,leave=False):\n",
    "            \n",
    "                km = TimeSeriesKMeans(n_clusters=n_clusters, verbose=False, random_state=0,n_jobs=20)\n",
    "                y_pred = km.fit_predict(X_train)\n",
    "                elbow_data.append((n_clusters, km.inertia_))\n",
    "        \n",
    "            k_range = []\n",
    "            inertias = []\n",
    "            for elb in elbow_data:\n",
    "                k_range.append(elb[0])\n",
    "                inertias.append(elb[1])\n",
    "\n",
    "            # ------------------------------------    \n",
    "            # Elbow KMeans estimation\n",
    "            kn = KneeLocator(k_range, inertias,S=2, curve='convex', direction='decreasing')\n",
    "            elbow_point = kn.knee+1\n",
    "            \n",
    "            # ------------------------------------\n",
    "            # Elbow KMeans plot\n",
    "            \n",
    "            fig_elb, ax_elb = plt.subplots(figsize=(10,5))\n",
    "            \n",
    "            ax_elb.annotate(str(elbow_point), xy=(elbow_point,inertias[k_range.index(elbow_point)]), xytext=(elbow_point+(elbow_point*0.5),inertias[k_range.index(elbow_point)]+(inertias[k_range.index(elbow_point)]*0.5)),arrowprops=dict(arrowstyle='<-',linewidth=0.25,color='black'))\n",
    "            ax_elb.scatter(elbow_point,inertias[k_range.index(elbow_point)],color='k', marker='X',s=100)\n",
    "            ax_elb.plot(k_range,inertias,color='grey', marker='o', linestyle='dashed',linewidth=2, markersize=5,zorder=-1)\n",
    "            ax_elb.text(0.85, 0.9,seletected_STA,fontweight='bold', fontsize=25, ha='right',va='center',transform=ax_elb.transAxes)\n",
    "            \n",
    "            # Set ticks and labels on both sides of the y-axis\n",
    "            ax_elb.set_xlim(0,10)\n",
    "            ax_elb.set_ylabel('Inertias')\n",
    "            ax_elb.set_xlabel('Values of K')\n",
    "            fig_elb.savefig(FOLDER_OUTPUT+'FIGURAS/PSD/LF/'+seletected_STA+'/LF_'+seletected_STA+'_Elbow_plot.png',pad_inches=0.02,dpi=200)\n",
    "\n",
    "            # ------------------------------------\n",
    "            # Euclidean k-means\n",
    "           \n",
    "            n_clu = elbow_point\n",
    "            km = TimeSeriesKMeans(n_clusters=n_clu, verbose=False, random_state=0)\n",
    "            y_pred = km.fit_predict(X_train)\n",
    "            \n",
    "            df_grouped['k-means'] = y_pred\n",
    "            \n",
    "            ################################\n",
    "            ##### CREATING THE FIGURE ######\n",
    "            ################################\n",
    "            \n",
    "            fig = plt.figure(figsize=(20,10))\n",
    "            gs = gridspec.GridSpec(3, n_clu)\n",
    "            \n",
    "            ax_psd_HF = fig.add_subplot(gs[:2, :])\n",
    "               \n",
    "            # Plot PSD computed via both methods\n",
    "            for i in df_grouped.iterrows():\n",
    "                year_quarter = i[1]['endtime']\n",
    "                color = cmap(norm(mdates.date2num(year_quarter)))\n",
    "                ax_psd_HF.plot(i[1]['freq_FFT_HF'], i[1]['data_FFT_HF'], color=color, lw=lw, alpha=alpha)\n",
    "            \n",
    "            ax_psd_HF.plot(df_grouped['freq_FFT_HF'].mean(),df_grouped['data_FFT_HF'].mean(), color='k', lw=2)\n",
    "            ax_psd_HF.text(0.9, 0.9,'Total = '+str(df_grouped.shape[0]),fontweight='bold', fontsize=12, ha='center',va='center',transform=ax_psd_HF.transAxes)\n",
    "            ax_psd_HF.text(0.1, 0.9,seletected_STA,fontweight='bold', fontsize=15, ha='right',va='center',transform=ax_psd_HF.transAxes)\n",
    "            \n",
    "            ax_psd_HF.set_ylabel('Spectral level (dB)')\n",
    "            \n",
    "            # Set limits for x-axes\n",
    "            ax_psd_HF.set_xlim(1, 50)\n",
    "            ax_psd_HF.set_ylim(-120,-20)\n",
    "            \n",
    "            # Set ticks and labels on both sides of the y-axis\n",
    "            ax_psd_HF.yaxis.set_tick_params(labelright=True,left=True, right=True)  # Show labels on the right side\n",
    "            ax_psd_HF.spines['top'].set_linewidth(2)\n",
    "            ax_psd_HF.spines['right'].set_linewidth(2)\n",
    "            ax_psd_HF.spines['bottom'].set_linewidth(2)\n",
    "            ax_psd_HF.spines['left'].set_linewidth(2)\n",
    "            ax_psd_HF.xaxis.set_tick_params(width=2)\n",
    "            ax_psd_HF.yaxis.set_tick_params(width=2)\n",
    "            \n",
    "            ax_psd_HF.xaxis.set_major_locator(majorX)\n",
    "            ax_psd_HF.xaxis.set_minor_locator(minorX)\n",
    "            ax_psd_HF.yaxis.set_major_locator(majorY)\n",
    "            ax_psd_HF.yaxis.set_minor_locator(minorY)\n",
    "            \n",
    "            # =======================================================================================================================================\n",
    "            \n",
    "            # Get unique k-means\n",
    "            unique_k_means = sorted(df_grouped['k-means'].unique())\n",
    "            \n",
    "            for k in unique_k_means:\n",
    "                ax = fig.add_subplot(gs[2, k])\n",
    "            \n",
    "                df_k = df_grouped[df_grouped['k-means'] == k]\n",
    "            \n",
    "                # Plot PSD computed via both methods\n",
    "                for i in df_k.iterrows():\n",
    "                    year_quarter = i[1]['endtime']\n",
    "                    color = cmap(norm(mdates.date2num(year_quarter)))\n",
    "                    ax.plot(i[1]['freq_FFT_HF'], i[1]['data_FFT_HF'], color=color, lw=lw, alpha=alpha)\n",
    "                ax.plot(df_k['freq_FFT_HF'].mean(),df_k['data_FFT_HF'].mean(), color='k', lw=2)\n",
    "                ax.text(0.5, 0.8,'Cluster %d' % (k + 1)+'\\n(n='+str(df_k.shape[0])+')',fontweight='bold', fontsize=12, ha='center',transform=ax.transAxes)\n",
    "            \n",
    "                ax.set_xlabel('Frequency (Hz)')\n",
    "                ax.set_ylim(-120,-20)\n",
    "                ax.set_xlim(1, 50)\n",
    "            \n",
    "                ax.spines['top'].set_linewidth(2)\n",
    "                ax.spines['right'].set_linewidth(2)\n",
    "                ax.spines['bottom'].set_linewidth(2)\n",
    "                ax.spines['left'].set_linewidth(2)\n",
    "                ax.xaxis.set_tick_params(width=2)\n",
    "                ax.yaxis.set_tick_params(width=2)  \n",
    "            \n",
    "                ax.xaxis.set_major_locator(majorX)\n",
    "                ax.xaxis.set_minor_locator(minorX)\n",
    "                ax.yaxis.set_major_locator(majorY)\n",
    "                ax.yaxis.set_minor_locator(minorY)\n",
    "                ax.yaxis.set_tick_params(labelright=False,labelleft=False,left=True, right=True)  # Show labels on the right side\n",
    "            \n",
    "                if k == unique_k_means[0]:\n",
    "                    ax.yaxis.set_tick_params(labelright=False,labelleft=True,left=True, right=True)  # Show labels on the right side\n",
    "                    ax.set_ylabel('Spectral level (dB)')\n",
    "            \n",
    "                if k == unique_k_means[-1]:\n",
    "                    ax.yaxis.set_tick_params(labelright=True,labelleft=False,left=True, right=True)  # Show labels on the right side\n",
    "            \n",
    "            # Create a color bar\n",
    "            # Create a scalar mappable for the colorbar\n",
    "            sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=mdates.date2num(df_grouped['endtime'].values[0]), vmax=mdates.date2num(df_grouped['endtime'].values[-1])))\n",
    "            \n",
    "            # Create the colorbar\n",
    "            cbar = fig.colorbar(sm,ax=ax_psd_HF,orientation='vertical')\n",
    "            cbar.set_label('Days of the year')\n",
    "            \n",
    "            # Set the ticks and tick labels for the colorbar\n",
    "            ticks = np.linspace(cbar.vmin, cbar.vmax, 6)  # Gera ticks uniformemente espaçados\n",
    "            cbar.set_ticks(ticks)\n",
    "            cbar.ax.yaxis.set_major_formatter(mdates.DateFormatter('%d/%m/%Y'))\n",
    "\n",
    "            fig.savefig(FOLDER_OUTPUT+'FIGURAS/PSD/LF/'+seletected_STA+'/LF_'+seletected_STA+'_KMeans.png',pad_inches=0.02,dpi=200)\n",
    "        \n",
    "            # =======================================================================================================================================\n",
    "            # Saving \n",
    "            # =======================================================================================================================================\n",
    "            df_grouped.to_feather(FOLDER_OUTPUT+'FIGURAS/PSD/LF/'+seletected_STA+'/df_psd_LF_'+seletected_STA+'_KMeans.feather') \n",
    "        \n",
    "            # ----------------------------------------------------------------------------------------------------------\n",
    "            # Close the figure after savig \n",
    "            # ----------------------------------------------------------------------------------------------------------                             \n",
    "                                            \n",
    "            plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a31c60d-5c31-4a78-963c-83c68e9255ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
