{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0288b9de",
   "metadata": {},
   "source": [
    "# Importando módulos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e98d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import obspy\n",
    "from obspy.taup import TauPyModel\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from obspy import read,UTCDateTime,Trace\n",
    "from obspy.clients.fdsn import Client\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import glidertools as gt\n",
    "\n",
    "#para plotar as figuras\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.transforms import offset_copy\n",
    "import matplotlib.ticker as ticker\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.dates as mdates\n",
    "from mpl_toolkits.axes_grid1.inset_locator import InsetPosition,inset_axes\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.dates import YearLocator, MonthLocator, DayLocator, HourLocator, MinuteLocator, SecondLocator, DateFormatter\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
    "\n",
    "from datetime import datetime,timedelta,date\n",
    "from tqdm import tqdm\n",
    "\n",
    "from shapely.geometry.polygon import LinearRing\n",
    "\n",
    "import cartopy.io.shapereader as shpreader\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4f9f8f",
   "metadata": {},
   "source": [
    "# Inputs e Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38736b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_OUTPUT = '/home/dIOGOLOC/dados_posdoc/gliders_project/OUTPUT/'\n",
    "\n",
    "FEATHER_OUTPUT = '/run/media/dIOGOLOC/8d2362fc-3b46-49a7-a864-19b2a6ad097b/diogoloc/dados_posdoc/gliders_project/OUTPUT/FEATHER/'\n",
    "\n",
    "\n",
    "MSEED_INPUT = \"/run/media/dIOGOLOC/8d2362fc-3b46-49a7-a864-19b2a6ad097b/diogoloc/dados_posdoc/gliders_project/OUTPUT/MSEED/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebce2fe",
   "metadata": {},
   "source": [
    "# Extraindo informações dos arquivos \".mseed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a67b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_MSEED = sorted(glob.glob(MSEED_INPUT+'*/*/*.mseed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2378588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mseed_data_2_dataframe(i):\n",
    "    subdir, filename_wav = os.path.split(i)\n",
    "    filename = filename_wav.split('.mseed')[0]\n",
    "    if 'pa' in filename.split('_')[0]:\n",
    "        mergulho = filename.split('_')[0].split('a')[1]\n",
    "        stream_number = filename.split('_')[1]\n",
    "\n",
    "        year_month_day = filename.split('_')[2]\n",
    "        hour_minute_second = filename.split('_')[3]\n",
    "\n",
    "        year = int('20'+year_month_day[:2])\n",
    "        month = int(year_month_day[2:4])\n",
    "        day = int(year_month_day[4:])\n",
    "\n",
    "        hour = int(hour_minute_second[:2])\n",
    "        minute = int(hour_minute_second[2:4])\n",
    "        second = int(hour_minute_second[4:])\n",
    "\n",
    "        d = UTCDateTime(datetime(year,month,day,hour,minute,second).isoformat())\n",
    "\n",
    "\n",
    "    if 'pa' in filename.split('_')[2]:\n",
    "\n",
    "        mergulho = filename.split('_')[2].split('a')[1]\n",
    "        stream_number = filename.split('_')[3]\n",
    "\n",
    "        year_month_day = filename.split('_')[0]\n",
    "        hour_minute_second = filename.split('_')[1]\n",
    "\n",
    "        year = int('20'+year_month_day[:2])\n",
    "        month = int(year_month_day[2:4])\n",
    "        day = int(year_month_day[4:])\n",
    "\n",
    "        hour = int(hour_minute_second[:2])\n",
    "        minute = int(hour_minute_second[2:4])\n",
    "        second = int(hour_minute_second[4:])\n",
    "\n",
    "        d = UTCDateTime(datetime(year,month,day,hour,minute,second).isoformat())\n",
    "        \n",
    "    \n",
    "    st = read(i,headonly=True)   \n",
    "    #----------------------------\n",
    "    #Starting Dataframe\n",
    "\n",
    "    starttime = st[0].stats.starttime.datetime\n",
    "    endtime = st[0].stats.endtime.datetime\n",
    "    sampling_rate = st[0].stats.sampling_rate\n",
    "    npts = st[0].stats.npts\n",
    "\n",
    "    \n",
    "    df = pd.DataFrame([[filename],[mergulho],[stream_number],[starttime],[endtime],[sampling_rate],[npts]], index=['filename_mseed', 'mergulho', 'stream_number','starttime','endtime','sampling_rate','npts']).T\n",
    "    \n",
    "    #Ending Dataframe\n",
    "    #----------------------------\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4c7652",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_mseed_lst = []\n",
    "\n",
    "with Pool(processes=8) as p:\n",
    "    max_ = len(filenames_MSEED)\n",
    "    with tqdm(total=max_) as pbar:\n",
    "        for result in p.imap_unordered(mseed_data_2_dataframe,filenames_MSEED):\n",
    "            pbar.update()\n",
    "            pandas_mseed_lst.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1380549",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_mseed_final = pd.concat(pandas_mseed_lst, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a6ca54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_mseed_final.sort_values(by='starttime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d4790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_mseed_final['duration'] = (dataframe_mseed_final['endtime'] - dataframe_mseed_final['starttime']).dt.total_seconds() / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed41fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_mseed_final.sort_values(by='starttime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bda6feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_mseed_final_duration = dataframe_mseed_final.groupby(\"stream_number\")['duration'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7f3317",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_mseed_final_duration_max = dataframe_mseed_final.groupby(\"stream_number\")['duration'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f185dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_mseed_final_duration_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ea8652",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_mseed_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5820068",
   "metadata": {},
   "outputs": [],
   "source": [
    "ano_lst = sorted(list(set(dataframe_mseed_final['starttime'].dt.year)))\n",
    "ano_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b8d424",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(ano_lst),2,sharex='col',figsize=(16,9))\n",
    "\n",
    "for i,j in enumerate(ano_lst):\n",
    "    ax = axes[i][0]\n",
    "    ax1 = axes[i][1]\n",
    "    # ------\n",
    "    # Stream\n",
    "    # ------\n",
    "    dataframe_mseed_final_year = dataframe_mseed_final[dataframe_mseed_final['starttime'].dt.year == j]\n",
    "\n",
    "    dataframe_mseed_final_duration = dataframe_mseed_final_year.groupby(\"stream_number\")['duration'].mean()\n",
    "    dataframe_mseed_final_duration_max = dataframe_mseed_final_year.groupby(\"stream_number\")['duration'].max()\n",
    "    \n",
    "    # Plotar o histograma da coluna\n",
    "    ax.hist(sorted(dataframe_mseed_final_year['stream_number']), bins=len(dataframe_mseed_final_year['stream_number'].unique())*1, ec='k',fc='k')\n",
    "\n",
    "    # Configurar o título e rótulos dos eixos\n",
    "    ax.set_ylabel('Frequência')\n",
    "    \n",
    "    ax.text(0.95, 0.9, 'ano: '+str(j), fontsize=12, ha='right', va='center', transform=ax.transAxes)\n",
    "    ax.text(0.95, 0.75, 'arquivos(n): '+str(len(dataframe_mseed_final_year)), fontsize=12, ha='right', va='center', transform=ax.transAxes)\n",
    "\n",
    "    # Set major xticks\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(10))\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # Set minor xticks\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(1))\n",
    "\n",
    "\n",
    "    # --------\n",
    "    # Duration\n",
    "    # --------\n",
    "\n",
    "    # Plotar o histograma da coluna\n",
    "    ax1.bar(x=dataframe_mseed_final_duration_max.index.values,height=dataframe_mseed_final_duration_max.values,align='edge',width=1,alpha=1,ec='k',fc='k',label='Max')\n",
    "    ax1.bar(x=dataframe_mseed_final_duration.index.values,height=dataframe_mseed_final_duration.values,align='edge',width=1,alpha=1,ec='gray',fc='none',label='Média')\n",
    "\n",
    "    # Configurar o título e rótulos dos eixos\n",
    "    ax1.set_ylabel('Duração (min)')\n",
    "    ax1.set_ylim(0,10)\n",
    "    \n",
    "    ax1.text(0.95, 0.9, 'ano: '+str(j), fontsize=12, ha='right', va='center', transform=ax1.transAxes)\n",
    "    ax1.text(0.95, 0.75, 'média(min): '+str(round(dataframe_mseed_final_duration.values.mean(),2)), fontsize=12, ha='right', va='center', transform=ax1.transAxes)\n",
    "\n",
    "    # Set major ticks\n",
    "    ax1.xaxis.set_major_locator(MultipleLocator(10))\n",
    "    ax1.yaxis.set_major_locator(MultipleLocator(5))\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # Set minor ticks\n",
    "    ax1.xaxis.set_minor_locator(MultipleLocator(1))\n",
    "    ax1.yaxis.set_minor_locator(MultipleLocator(1))\n",
    "\n",
    "    # Add a legend to the plot\n",
    "    ax1.legend(loc='upper center')\n",
    "    \n",
    "    # -----\n",
    "    \n",
    "    if i == len(axes):\n",
    "        ax.set_xlabel('Stream (nº)')\n",
    "        ax1.set_xlabel('Stream (nº)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bccb0c9",
   "metadata": {},
   "source": [
    "# Extraindo informações dos arquivos \".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0377fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_csv = '/run/media/dIOGOLOC/8d2362fc-3b46-49a7-a864-19b2a6ad097b/diogoloc/dados_posdoc/gliders_project/gliders_data/info_csv/metadados_glider_acustico_pmpas-bs.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa226236",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_csv = pd.read_csv(filename_csv,parse_dates=['time'])\n",
    "dataframe_csv.sort_values(by='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063c1023",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = dataframe_csv.groupby(\"filename\").agg(pd.Series.tolist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c74ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8103f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv['filename_mseed'] = df_csv.index.str.replace('_rms_spl3.mat', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fe0a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv.sort_values(by='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b3be7c",
   "metadata": {},
   "source": [
    "# Aglutinando os dataframes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0f9f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_csv_mseed = df_csv.merge(dataframe_mseed_final, on='filename_mseed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d244b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_csv_mseed['time_timestamp'] = merged_df_csv_mseed['time'].apply(lambda x: [pd.to_datetime(date).timestamp() for date in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088fbdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_csv_mseed.sort_values(by='starttime')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660e57a3",
   "metadata": {},
   "source": [
    "# Interpolando os dados de profundidade, latitude, longitude em função da série temporal através do numpy interp:\n",
    "\n",
    "One-dimensional linear interpolation for monotonically increasing sample points.\n",
    "\n",
    "Returns the one-dimensional piecewise linear interpolant to a function\n",
    "with given discrete data points (`xp`, `fp`), evaluated at `x`.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "x : array_like\n",
    "    The x-coordinates at which to evaluate the interpolated values.\n",
    "\n",
    "xp : 1-D sequence of floats\n",
    "    The x-coordinates of the data points, must be increasing if argument\n",
    "    `period` is not specified. Otherwise, `xp` is internally sorted after\n",
    "    normalizing the periodic boundaries with ``xp = xp % period``.\n",
    "\n",
    "fp : 1-D sequence of float or complex\n",
    "    The y-coordinates of the data points, same length as `xp`.\n",
    "\n",
    "left : optional float or complex corresponding to fp\n",
    "    Value to return for `x < xp[0]`, default is `fp[0]`.\n",
    "\n",
    "right : optional float or complex corresponding to fp\n",
    "    Value to return for `x > xp[-1]`, default is `fp[-1]`.\n",
    "\n",
    "period : None or float, optional\n",
    "    A period for the x-coordinates. This parameter allows the proper\n",
    "    interpolation of angular x-coordinates. Parameters `left` and `right`\n",
    "    are ignored if `period` is specified.\n",
    "\n",
    "    .. versionadded:: 1.10.0\n",
    "\n",
    "Returns\n",
    "-------\n",
    "y : float or complex (corresponding to fp) or ndarray\n",
    "    The interpolated values, same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affade1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp_dataframe_depth_lat_lon_time(filename_mseed,df=merged_df_csv_mseed,filenames_MSEED_lst=filenames_MSEED):\n",
    "    new_df = df[df['filename_mseed'] == filename_mseed]\n",
    "    # Dados de profundidade, latitude, longitude e tempo numérico\n",
    "    profundidade = new_df['depth'].values[0]\n",
    "    latitude = new_df['latitude'].values[0]\n",
    "    longitude = new_df['longitude'].values[0]\n",
    "    tempo_numerico = new_df['time_timestamp'].values[0]\n",
    "\n",
    "    # Importar array de tempo interpolado\n",
    "    for i in filenames_MSEED_lst:\n",
    "        if filename_mseed in i:\n",
    "            st = read(i,headonly=True)   \n",
    "            tempo_interpolado_numerico = st[0].times('timestamp')\n",
    "            tempo_interpolado = [k.datetime for k in st[0].times(\"utcdatetime\")]\n",
    "            tempo_obspy_times = st[0].times()\n",
    "\n",
    "    # Interpolar os dados de profundidade usando numpy.interp\n",
    "    profundidade_interpolada = np.interp(tempo_interpolado_numerico, tempo_numerico, profundidade)\n",
    "\n",
    "    # Interpolar os dados de latitude usando numpy.interp\n",
    "    latitude_interpolada = np.interp(tempo_interpolado_numerico, tempo_numerico, latitude)\n",
    "\n",
    "    # Interpolar os dados de longitude usando numpy.interp\n",
    "    longitude_interpolada = np.interp(tempo_interpolado_numerico, tempo_numerico, longitude)\n",
    "\n",
    "    # Salvar os resultados\n",
    "    df_interpolado = pd.DataFrame({'filename_mseed':filename_mseed+'.mseed',\n",
    "                                   'Time_interp': tempo_interpolado, \n",
    "                                   'depth_interp': profundidade_interpolada, \n",
    "                                   'latitude_interp': latitude_interpolada, \n",
    "                                   'longitude_interp': longitude_interpolada})\n",
    "    \n",
    "    # Salvar o DataFrame em um arquivo Feather\n",
    "    year = st[0].times(\"utcdatetime\")[0].strftime('%Y')\n",
    "    pasta_dia = st[0].times(\"utcdatetime\")[0].strftime('%Y-%m-%d')\n",
    "    output_folder_feather = FEATHER_OUTPUT+'/'+year+'/'+pasta_dia+'/'\n",
    "    os.makedirs(output_folder_feather,exist_ok=True)\n",
    "    df_interpolado.to_feather(output_folder_feather+filename_mseed+'.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6172f290",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(processes=4) as p:\n",
    "    max_ = len(merged_df_csv_mseed['filename_mseed'])\n",
    "    with tqdm(total=max_) as pbar:\n",
    "        for _ in p.imap_unordered(interp_dataframe_depth_lat_lon_time,merged_df_csv_mseed['filename_mseed']):\n",
    "            pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f12e724",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
